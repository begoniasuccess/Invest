import requests
import pandas as pd
from datetime import datetime, timedelta
from dateutil.relativedelta import relativedelta
import os
import requests
import calendar
from db import query_to_df, execute_sql, get_connection, query_single
import json

twseUrl = "https://www.twse.com.tw/rwd/zh"
data_center = "../data/TwStockExchange"
common_params = "response=json"

# ======== å…±ç”¨å·¥å…· ========
def _date_to_str(date: datetime = None, formate: str = None) -> str:
    """å°‡ datetime è½‰ç‚º yyyymmdd å­—ä¸²ï¼Œè‹¥æœªæŒ‡å®šå‰‡å–ä»Šæ—¥"""
    if date is None:
        date = datetime.today()
    if formate is None:
        formate = "%Y%m%d"
    return date.strftime(formate)

def _save_to_csv(df: pd.DataFrame, apiEndpoint: str, filename: str):
    # 1. æª¢æŸ¥ data_center æ˜¯å¦å­˜åœ¨
    if not os.path.exists(data_center):
        raise FileNotFoundError(f"âŒ data_center ä¸å­˜åœ¨ï¼š{data_center}")
    
    # 2. ç¢ºä¿ç›®æ¨™è³‡æ–™å¤¾å­˜åœ¨
    dir_path = os.path.join(data_center, apiEndpoint)
    os.makedirs(dir_path, exist_ok=True)  # å¦‚æœä¸å­˜åœ¨å°±å»ºç«‹
    
    path = os.path.join(dir_path, f"{filename}.csv")
    
    # 3. å„²å­˜ CSV
    df.to_csv(path, index=False, encoding="utf-8-sig")
    print(f"âœ… å·²å„²å­˜ï¼š{path}")

def _read_from_csv(apiEndpoint: str, filename: str) -> pd.DataFrame:
    # 1. æª¢æŸ¥ data æ˜¯å¦å­˜åœ¨
    dir_path = os.path.join(data_center, apiEndpoint)    
    path = os.path.join(dir_path, f"{filename}.csv")

    if not os.path.exists(path):
        print(f"âŒ CSVæª”æ¡ˆ ä¸å­˜åœ¨ï¼š{path}")
        return None
    
    df = pd.read_csv(path)
    return df

def _cleanup_old_files(dir_path: str, stock_no: str, date_str: str, keep: str):
    """åˆªé™¤åŒæœˆä»½ä¸­é™¤äº† keep çš„å…¶ä»–æª”æ¡ˆ"""
    for f in os.listdir(dir_path):
        if f.startswith(f"{stock_no}_{date_str}") and f.endswith(".csv") and f != keep:
            try:
                os.remove(os.path.join(dir_path, f))
                print(f"ğŸ§¹ å·²åˆªé™¤èˆŠæª”ï¼š{f}")
            except Exception as e:
                print(f"âš ï¸ ç„¡æ³•åˆªé™¤ {f}: {e}")

def _to_roc_date(dt: datetime) -> str:
    """å°‡ datetime è½‰æˆæ°‘åœ‹å¹´æœˆæ—¥æ ¼å¼ï¼ˆyyy.mm.ddï¼‰"""
    roc_year = dt.year - 1911
    return f"{roc_year:03d}.{dt.month:02d}.{dt.day:02d}"

def _roc_to_datetime(roc_date: str) -> datetime:
    """
    å°‡æ°‘åœ‹å¹´æ—¥æœŸå­—ä¸²è½‰æˆ datetime
    ä¾‹å¦‚ "114.04.11" â†’ datetime(2025, 4, 11)
    """
    try:
        parts = roc_date.split(".")
        if len(parts) != 3:
            raise ValueError("æ ¼å¼éŒ¯èª¤ï¼Œæ‡‰ç‚º yyy.mm.dd")
        year = int(parts[0]) + 1911  # æ°‘åœ‹å¹´è½‰è¥¿å…ƒå¹´
        month = int(parts[1])
        day = int(parts[2])
        return datetime(year, month, day)
    except Exception as e:
        print(f"[Error] è½‰æ›å¤±æ•—: {roc_date} ({e})")
        return None
    
def _is_fully_in_range(sDt: datetime, eDt: datetime, minDt: datetime, maxDt: datetime) -> bool:
    """
    åˆ¤æ–·å€é–“ sDt~eDt æ˜¯å¦å®Œå…¨åŒ…å«åœ¨ minDt~maxDt å…§
    å›å‚³å¸ƒæ—å€¼
    """
    return minDt <= sDt <= maxDt and minDt <= eDt <= maxDt

def _is_no_overlap(sDt: datetime, eDt: datetime, minDt: datetime, maxDt: datetime) -> bool:
    """
    åˆ¤æ–·å€é–“ sDt~eDt æ˜¯å¦èˆ‡ minDt~maxDt å®Œå…¨ä¸é‡ç–Š
    å›å‚³å¸ƒæ—å€¼
    """
    return eDt < minDt or sDt > maxDt


# ======== 1. å€‹è‚¡æˆäº¤æ—¥è³‡è¨Š (å«å¿«å–ã€åˆä½µã€æ¸…ç†æ©Ÿåˆ¶) ========
# æ—¥æœŸ,æˆäº¤è‚¡æ•¸,æˆäº¤é‡‘é¡,é–‹ç›¤åƒ¹,æœ€é«˜åƒ¹,æœ€ä½åƒ¹,æ”¶ç›¤åƒ¹,æ¼²è·Œåƒ¹å·®,æˆäº¤ç­†æ•¸
def get_stock_day(stock_no: str, date: datetime | None = None) -> pd.DataFrame:
    today = datetime.today()
    date = (date or today).replace(day=1)
    date_str = date.strftime("%Y%m")
    apiEndpoint = "afterTrading/STOCK_DAY"
    dir_path = os.path.join(data_center, apiEndpoint)
    os.makedirs(dir_path, exist_ok=True)

    # å˜—è©¦å®Œæ•´æª”
    df = _read_from_csv(apiEndpoint, f"{stock_no}_{date_str}")
    if df is not None:
        print(f"ğŸ“‚ æª”æ¡ˆå·²å­˜åœ¨ï¼š{stock_no}_{date_str}.csv")
        return df

    # å‘¼å« API
    apiUrl = f"{twseUrl}/{apiEndpoint}?date={date.strftime('%Y%m%d')}&stockNo={stock_no}&{common_params}"
    res = requests.get(apiUrl).json()
    df = pd.DataFrame(res.get("data", []), columns=res.get("fields", []))

    if df.empty:
        print("âš ï¸ API å›å‚³ç©ºè³‡æ–™")
        return df

    # è™•ç†æ°‘åœ‹å¹´æ—¥æœŸï¼ˆä¾‹å¦‚ '114/10/03' â†’ '20241003'ï¼‰
    raw = df.iloc[-1, 0].replace("/", "")
    if len(raw) == 7:  # æ°‘åœ‹å¹´æ ¼å¼
        raw = str(int(raw[:3]) + 1911) + raw[3:]
    last_date = datetime.strptime(raw, "%Y%m%d")

    # åˆ¤æ–·æ˜¯å¦ç‚ºç•¶æœˆï¼ˆå°šæœªçµæŸçš„æœˆï¼‰
    is_current_month = date.year == today.year and date.month == today.month
    if not is_current_month:
        # éå»æœˆä»½ä¸€å®šå­˜æˆå®Œæ•´æœˆæª”
        filename = f"{stock_no}_{date_str}"
    else:
        # æœ¬æœˆå°šæœªçµæŸï¼Œå¯èƒ½ä¸å®Œæ•´
        days_in_month = calendar.monthrange(date.year, date.month)[1]
        if last_date.day == days_in_month:
            filename = f"{stock_no}_{date_str}"
        else:
            filename = f"{stock_no}_{date.strftime('%Y%m%d')}_{last_date.strftime('%Y%m%d')}"

    _save_to_csv(df, apiEndpoint, filename)
    _cleanup_old_files(dir_path, stock_no, date_str, keep=f"{filename}.csv")

    return df

# ======== 2. å€‹è‚¡æ”¶ç›¤åƒ¹ ========
# æ—¥æœŸ,æ”¶ç›¤åƒ¹
def get_stock_day_avg(stock_no: str, date: datetime | None = None) -> pd.DataFrame:
    today = datetime.today()
    date = (date or today).replace(day=1)
    date_str = date.strftime("%Y%m")
    apiEndpoint = "afterTrading/STOCK_DAY_AVG"
    dir_path = os.path.join(data_center, apiEndpoint)
    os.makedirs(dir_path, exist_ok=True)

    # å˜—è©¦å®Œæ•´æª”
    df = _read_from_csv(apiEndpoint, f"{stock_no}_{date_str}")
    if df is not None:
        print(f"ğŸ“‚ æª”æ¡ˆå·²å­˜åœ¨ï¼š{stock_no}_{date_str}.csv")
        return df

    # å‘¼å« API
    apiUrl = f"{twseUrl}/{apiEndpoint}?date={date.strftime('%Y%m%d')}&stockNo={stock_no}&{common_params}"
    res = requests.get(apiUrl).json()
    df = pd.DataFrame(res.get("data", []), columns=res.get("fields", []))

    if df.empty:
        print("âš ï¸ API å›å‚³ç©ºè³‡æ–™")
        return df

    # æ‰¾æœ€å¾Œä¸€å€‹åˆæ³•æ—¥æœŸï¼ˆæ’é™¤éæ—¥æœŸåˆ—ï¼Œä¾‹å¦‚æœˆå¹³å‡æ”¶ç›¤åƒ¹ï¼‰
    date_col = df.columns[0]  # å‡è¨­ç¬¬ä¸€æ¬„æ˜¯æ—¥æœŸ
    for d in reversed(df[date_col]):
        raw = str(d).replace("/", "")
        if raw.isdigit() and (len(raw) == 7 or len(raw) == 8):
            # è™•ç†æ°‘åœ‹å¹´æ ¼å¼
            if len(raw) == 7:
                raw = str(int(raw[:3]) + 1911) + raw[3:]
            last_date = datetime.strptime(raw, "%Y%m%d")
            break
    else:
        raise ValueError("æ‰¾ä¸åˆ°æœ‰æ•ˆæ—¥æœŸæ¬„ä½")

    # åˆ¤æ–·æ˜¯å¦ç‚ºç•¶æœˆï¼ˆå°šæœªçµæŸçš„æœˆï¼‰
    is_current_month = date.year == today.year and date.month == today.month
    if not is_current_month:
        # éå»æœˆä»½ç›´æ¥å­˜å®Œæ•´æœˆæª”
        filename = f"{stock_no}_{date_str}"
    else:
        # æœ¬æœˆå°šæœªçµæŸ
        days_in_month = calendar.monthrange(date.year, date.month)[1]
        if last_date.day == days_in_month:
            filename = f"{stock_no}_{date_str}"
        else:
            filename = f"{stock_no}_{date.strftime('%Y%m%d')}_{last_date.strftime('%Y%m%d')}"

    # å„²å­˜ CSV ä¸¦æ¸…ç†èˆŠæª”
    _save_to_csv(df, apiEndpoint, filename)
    _cleanup_old_files(dir_path, stock_no, date_str, keep=f"{filename}.csv")

    return df

# ======== 3. ä¸‰å¤§æ³•äºº ========
# å–®ä½åç¨±,è²·é€²é‡‘é¡,è³£å‡ºé‡‘é¡,è²·è³£å·®é¡
def get_institutional_investors(date: datetime | None = None) -> pd.DataFrame:
    date_str = _date_to_str(date)
    apiEndpoint = "fund/BFI82U"
    apiParams = f"type=day&dayDate={date_str}&weekDate={date_str}&monthDate={date_str}&{common_params}"
    apiUrl = f"{twseUrl}/{apiEndpoint}?{apiParams}"

    res = requests.get(apiUrl)
    data = res.json()

    df = pd.DataFrame(data.get("data", []), columns=data.get("fields", []))
    _save_to_csv(df, apiEndpoint, f"{date_str}")
    return df

# ======== 3.2 ä¸‰å¤§æ³•äºº å€é–“ç‰ˆ ========
# å–®ä½åç¨±,è²·é€²é‡‘é¡,è³£å‡ºé‡‘é¡,è²·è³£å·®é¡
def get_institutional_investors_range(startDate: datetime, endDate: datetime) -> pd.DataFrame:
    apiEndpoint = "fund/BFI82U"
    all_data = []
    current = startDate
    while current <= endDate:
        date_str = _date_to_str(current)
        apiParams = f"type=day&dayDate={date_str}&weekDate={date_str}&monthDate={date_str}&{common_params}"
        apiUrl = f"{twseUrl}/{apiEndpoint}?{apiParams}"

        res = requests.get(apiUrl)
        data = res.json()

        # å¦‚æœ API å›å‚³ä¸æ˜¯ OK æˆ–æ²’æœ‰è³‡æ–™ï¼Œè·³é
        if data.get("stat") != "OK" or "data" not in data:
            print(f"âš ï¸ {date_str} æ²’æœ‰è³‡æ–™ï¼Œå·²è·³é")
            current += timedelta(days=1)
            continue

        df_day = pd.DataFrame(data["data"], columns=data["fields"])
        df_day.insert(0, "æ—¥æœŸ", date_str)  # åŠ ä¸Šæ—¥æœŸæ¬„ä½
        all_data.append(df_day)

        current += timedelta(days=1)

    # åˆä½µæ‰€æœ‰æ—¥æœŸçš„è³‡æ–™
    if not all_data:
        raise ValueError("âŒ å€é–“å…§æ²’æœ‰ä»»ä½•æœ‰æ•ˆè³‡æ–™")

    df_all = pd.concat(all_data, ignore_index=True)

    # å­˜æˆä¸€å€‹ç¸½æª”æ¡ˆ
    filename = f"{_date_to_str(startDate)}_{_date_to_str(endDate)}"
    _save_to_csv(df_all, apiEndpoint, filename)

    return df_all

# ======== 4. èè³‡èåˆ¸é¤˜é¡ ========
# æ—¥æœŸ,é …ç›®,è²·é€²,è³£å‡º,ç¾é‡‘(åˆ¸)å„Ÿé‚„,å‰æ—¥é¤˜é¡,ä»Šæ—¥é¤˜é¡
def get_margin_trading(date: datetime | None = None) -> pd.DataFrame:
    date_str = _date_to_str(date)
    apiEndpoint = "marginTrading/MI_MARGN"
    apiParams = f"date={date_str}&selectType=MS&{common_params}"
    apiUrl = f"{twseUrl}/{apiEndpoint}?{apiParams}"

    res = requests.get(apiUrl)
    data = res.json()

    # tables[0] æ‰æœ‰è³‡æ–™
    tables = data.get("tables", [])
    if not tables or "fields" not in tables[0] or "data" not in tables[0]:
        raise ValueError(f"âŒ API å›å‚³æ ¼å¼ç•°å¸¸: {data}")

    fields = tables[0]["fields"]
    rows = tables[0]["data"]

    df = pd.DataFrame(rows, columns=fields)

    _save_to_csv(df, apiEndpoint, f"{date_str}")
    return df

# ======== 4.2 èè³‡èåˆ¸é¤˜é¡ å€é–“ç‰ˆ ========
# æ—¥æœŸ,é …ç›®,è²·é€²,è³£å‡º,ç¾é‡‘(åˆ¸)å„Ÿé‚„,å‰æ—¥é¤˜é¡,ä»Šæ—¥é¤˜é¡
def get_margin_trading_range(sDt: datetime, eDt: datetime) -> pd.DataFrame:
    apiEndpoint = "marginTrading/MI_MARGN"
    all_data = []

    current = sDt
    while current <= eDt:
        date_str = _date_to_str(current)
        apiParams = f"date={date_str}&selectType=MS&{common_params}"
        apiUrl = f"{twseUrl}/{apiEndpoint}?{apiParams}"

        res = requests.get(apiUrl)
        try:
            data = res.json()
        except ValueError:
            print("âš ï¸ API å›å‚³ä¸æ˜¯ JSONï¼")
            print(res.text)
            current += timedelta(days=1)
            continue

        # å¦‚æœå›å‚³åªæœ‰ "stat" ä¸”ä¸æ˜¯ "OK"ï¼Œè¡¨ç¤ºæ²’è³‡æ–™
        if data.get("stat") != "OK":
            print(f"âš ï¸ {date_str} æ²’æœ‰è³‡æ–™ï¼Œå·²è·³é")
            current += timedelta(days=1)
            continue

        tables = data.get("tables", [])
        if tables and "fields" in tables[0] and "data" in tables[0]:
            fields = tables[0]["fields"]
            rows = tables[0]["data"]

            df_day = pd.DataFrame(rows, columns=fields)
            df_day.insert(0, "æ—¥æœŸ", date_str)  # åŠ ä¸Šæ—¥æœŸæ¬„ä½
            all_data.append(df_day)
        else:
            print(f"âš ï¸ {date_str} API æ ¼å¼ç•°å¸¸ï¼Œå·²è·³é")

        current += timedelta(days=1)

    # åˆä½µæ‰€æœ‰æ—¥æœŸçš„è³‡æ–™
    if not all_data:
        raise ValueError("âŒ å€é–“å…§æ²’æœ‰ä»»ä½•æœ‰æ•ˆè³‡æ–™")

    df_all = pd.concat(all_data, ignore_index=True)

    # å­˜æˆä¸€å€‹ç¸½æª”æ¡ˆ
    filename = f"{_date_to_str(sDt)}_{_date_to_str(eDt)}"
    _save_to_csv(df_all, apiEndpoint, filename)

    return df_all

# ======== 5. æ³¨æ„è‚¡å…¬å‘Š ========
# ç·¨è™Ÿ,è­‰åˆ¸ä»£è™Ÿ,è­‰åˆ¸åç¨±,ç´¯è¨ˆæ¬¡æ•¸,æ³¨æ„äº¤æ˜“è³‡è¨Š,æ—¥æœŸ,æ”¶ç›¤åƒ¹,æœ¬ç›Šæ¯”
def get_notice(sDt: datetime | None = None, eDt: datetime | None = None):
    if eDt > datetime.today():
        eDt = datetime.today()

    start_str = _date_to_str(sDt)
    end_str = _date_to_str(eDt)

    ### å…ˆç¢ºèªåº«è³‡æ–™çš„ä¸Šä¸‹ç•Œ
    sql = "SELECT min(æ—¥æœŸ), MAX(æ—¥æœŸ) FROM twse_announcement_notice"
    df_check = query_to_df(sql)
    minDt = _roc_to_datetime(df_check["min(æ—¥æœŸ)"].iloc[0])
    maxDt = _roc_to_datetime(df_check["MAX(æ—¥æœŸ)"].iloc[0])
    print(minDt, maxDt)

    if (_is_fully_in_range(sDt, eDt, minDt, maxDt)):
        print("*** ç›´æ¥å¾åº«æå–è³‡æ–™")
        sql = "SELECT * FROM twse_announcement_notice"
        sql += f" WHERE æ—¥æœŸ between '{_to_roc_date(sDt)}' AND '{_to_roc_date(eDt)}'"
        print(sql)
        df = query_to_df(sql)
        return df
    
    print("*** å¾APIæå–è³‡æ–™")
    apiEndpoint = "announcement/notice"
    apiParams = f"querytype=1&stockNo=&selectType=&sortKind=STKNO&{common_params}"
    apiParams += f"&startDate={start_str}&endDate={end_str}"
    apiUrl = f"{twseUrl}/{apiEndpoint}?{apiParams}"

    res = requests.get(apiUrl)
    raw_data = res.json()
    data = raw_data["data"]

    ### å­˜åˆ°dbè£¡
    if (_is_no_overlap(sDt, eDt, minDt, maxDt)):
        values = []
        for r in data:
            try:
                pe = str(r[7]).strip()
                pe_value = float(pe) if pe.replace('.', '', 1).isdigit() else None
                if pe_value is None:
                    continue
                values.append((
                    r[1].strip(),
                    r[2].strip(),
                    int(r[3]),
                    r[4].strip(),
                    r[5].strip(),
                    float(r[6]),
                    pe_value
                ))
            except:
                continue

        sql = """
        INSERT OR REPLACE INTO twse_announcement_notice
        (è­‰åˆ¸ä»£è™Ÿ, è­‰åˆ¸åç¨±, ç´¯è¨ˆæ¬¡æ•¸, æ³¨æ„äº¤æ˜“è³‡è¨Š, æ—¥æœŸ, æ”¶ç›¤åƒ¹, æœ¬ç›Šæ¯”)
        VALUES (?, ?, ?, ?, ?, ?, ?)
        """
        execute_sql(sql, values)

    df = pd.DataFrame(raw_data.get("data", []), columns=raw_data.get("fields", []))
    _save_to_csv(df, apiEndpoint, f"{start_str}_{end_str}")
    return df


# ======== ç¯„ä¾‹æ¸¬è©¦ ========
if __name__ == "__main__":
    year = 2023
    sDt = datetime(2020, 1, 1)
    eDt = datetime(2020, 12, 31)
    testData = get_notice(sDt, eDt)
    print(testData.head())

    # test = datetime.today()
    # test = test - relativedelta(months=1)

    # # æ¸¬è©¦ä¸‹è¼‰å„é …è³‡æ–™
    # get_stock_day("2330", test)
    # get_stock_day_avg("0050", test)
    # get_institutional_investors(test)
    # get_margin_trading(test)
    # get_notice(datetime(2025, 10, 1), datetime(2025, 10, 4))
