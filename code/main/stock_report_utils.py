import numpy as np
import pandas as pd
from dateutil.relativedelta import relativedelta
from common import db

# =========================================================
# 0) å°å·¥å…·ï¼šåˆ¤æ–·ç¼ºå€¼ã€Series å–æ¬„ä½ã€é˜²å‘†åŠ ç¸½
# =========================================================
def _is_missing(v):
    if v is None:
        return True
    if isinstance(v, float) and np.isnan(v):
        return True
    if isinstance(v, str) and v.strip() == "":
        return True
    return False

def _scol(df_, col, default=np.nan):
    if col in df_.columns:
        s = df_[col]
        if isinstance(s, pd.Series):
            return s
        return pd.Series([s] * len(df_), index=df_.index)
    return pd.Series([default] * len(df_), index=df_.index)

def _sum_cols(df_, cols, default=0.0):
    out = pd.Series([0.0] * len(df_), index=df_.index, dtype="float64")
    hit = False
    for c in cols:
        if c in df_.columns:
            out = out + pd.to_numeric(_scol(df_, c, default=0.0), errors="coerce").fillna(0.0)
            hit = True
    if not hit:
        return pd.Series([default] * len(df_), index=df_.index, dtype="float64")
    return out

def _sum_cols_like(df_, keywords, default=0.0):
    cols = []
    for c in df_.columns:
        cs = str(c)
        if any(k in cs for k in keywords):
            cols.append(c)
    if not cols:
        return pd.Series([default] * len(df_), index=df_.index, dtype="float64")
    return _sum_cols(df_, cols, default=default)


# =========================================================
# 1) é‡æ–°æŠ“ã€Œå¯é‡å»ºå ±å‘Šæ‰€éœ€ã€çš„åŸå§‹è³‡æ–™ï¼ˆåƒ¹æ ¼/æ³•äºº/èè³‡ï¼‰
#    - é€™æ¨£ä½ å°±ç®— DB æŸäº›åŸå§‹æ¬„ä¹Ÿç¼ºï¼Œä»å¯é‡å»ºè¡ç”Ÿæ¬„
# =========================================================
def _build_base_df(finMind, stock_id, sDt, eDt):
    """
    å›å‚³ä»¥ã€Œdate(datetime)ã€ç‚ºä¸»éµã€åŒ…å«åƒ¹æ ¼ + æ³•äºº(æ·¨é¡) + èè³‡(ä»Šæ—¥é¤˜é¡) çš„ base df
    """
    df = finMind.get_tw_stock_daily_price(stock_id=stock_id, start_date=sDt, end_date=eDt)
    if df is None or df.empty:
        return pd.DataFrame()

    df = df.copy()
    df["date"] = pd.to_datetime(df["date"])
    df = df[df["date"] <= pd.to_datetime(eDt.date())].reset_index(drop=True)

    # æ³•äºº
    df3 = finMind.get_tw_institutional_total(start_date=sDt, end_date=eDt)
    if df3 is None or df3.empty:
        df3 = pd.DataFrame(columns=["buy", "sell", "date", "name"])
    else:
        df3 = df3.copy()
        df3["net"] = pd.to_numeric(df3.get("buy"), errors="coerce") - pd.to_numeric(df3.get("sell"), errors="coerce")
        df3["date"] = pd.to_datetime(df3["date"])
        df3 = df3.pivot(index="date", columns="name", values="net").reset_index()

    df = df.merge(df3, on="date", how="left")

    # èè³‡ï¼šä»Šæ—¥é¤˜é¡ï¼ˆä»Ÿå…ƒï¼‰
    df["ä»Šæ—¥é¤˜é¡"] = np.nan
    df_m = finMind.get_tw_margin_total(start_date=sDt, end_date=eDt)

    if df_m is not None and not df_m.empty:
        df_m = df_m.copy()
        col_date = "date" if "date" in df_m.columns else ("æ—¥æœŸ" if "æ—¥æœŸ" in df_m.columns else None)
        col_name = "name" if "name" in df_m.columns else ("é …ç›®" if "é …ç›®" in df_m.columns else None)
        col_today = "TodayBalance" if "TodayBalance" in df_m.columns else ("ä»Šæ—¥é¤˜é¡" if "ä»Šæ—¥é¤˜é¡" in df_m.columns else None)

        if col_date and col_name and col_today:
            df_m[col_date] = pd.to_datetime(df_m[col_date])
            df_m[col_name] = df_m[col_name].astype(str)

            cand = df_m[df_m[col_name] == "MarginPurchaseMoney"].copy()
            if not cand.empty:
                cand[col_today] = pd.to_numeric(cand[col_today], errors="coerce")
                med = cand[col_today].median(skipna=True)

                # heuristicï¼šå¤ªå¤§è¦–ç‚ºå…ƒ -> /1000 è½‰ä»Ÿå…ƒ
                if pd.notna(med) and med > 1e9:
                    cand["ä»Šæ—¥é¤˜é¡"] = cand[col_today] / 1000.0
                else:
                    cand["ä»Šæ—¥é¤˜é¡"] = cand[col_today]

                cand = cand[[col_date, "ä»Šæ—¥é¤˜é¡"]].rename(columns={col_date: "date"})
                df = df.merge(cand, on="date", how="left", suffixes=("", "_m"))
                if "ä»Šæ—¥é¤˜é¡_m" in df.columns:
                    df["ä»Šæ—¥é¤˜é¡"] = df["ä»Šæ—¥é¤˜é¡"].combine_first(df["ä»Šæ—¥é¤˜é¡_m"])
                    df.drop(columns=["ä»Šæ—¥é¤˜é¡_m"], inplace=True, errors="ignore")

    return df


# =========================================================
# 2) è¨ˆç®—å™¨ï¼ˆregistryï¼‰ï¼šæ¯å€‹æ¬„ä½ä¸€å€‹ functionï¼ˆå›å¯«åˆ° dfï¼‰
#    - ä½ å¯ä»¥æŒçºŒæ“´å……ï¼šæ–°å¢ key + å°æ‡‰è¨ˆç®—å‡½å¼å³å¯
# =========================================================
def _classify_k_type_row(r):
    body = r.get("å¯¦é«”_pct", np.nan)
    upper = r.get("ä¸Šå½±_pct", np.nan)
    lower = r.get("ä¸‹å½±_pct", np.nan)
    open_p = r.get("é–‹ç›¤åƒ¹", np.nan)
    close_p = r.get("æ”¶ç›¤åƒ¹", np.nan)

    if pd.isna(body) or pd.isna(upper) or pd.isna(lower):
        return None
    if pd.isna(open_p) or pd.isna(close_p):
        return None

    if abs(close_p - open_p) < 1e-6 or body < 0.05:
        return "â¬œ åå­—ç·š"

    is_red = close_p > open_p
    color = "ğŸŸ¥" if is_red else "ğŸŸ©"

    if lower > 0.5 and body < 0.3:
        return f"{color} éŒ˜å­ç·š"
    if upper > 0.5 and body < 0.3:
        return f"{color} æµæ˜Ÿç·š"
    if body > 0.6:
        return f"{color} é•·ç´…K" if is_red else f"{color} é•·é»‘K"
    return f"{color} ä¸­å¯¦é«”K"


def _compute_derived(df):
    """
    åªè¦ df å…§æœ‰åŸºæœ¬åƒ¹é‡æ¬„ï¼Œå°±èƒ½ç”Ÿå‡ºå¤§éƒ¨åˆ†è¡ç”Ÿæ¬„
    """
    # rename æˆä½ å ±å‘Šæ¬„å
    df = df.copy()
    df.rename(
        columns={
            "date": "æ—¥æœŸ",
            "open": "é–‹ç›¤åƒ¹",
            "close": "æ”¶ç›¤åƒ¹",
            "max": "æœ€é«˜åƒ¹",
            "min": "æœ€ä½åƒ¹",
            "Trading_Volume": "æˆäº¤é‡",
            "Trading_money": "ç¸½æˆäº¤é‡‘é¡_å„„",
        },
        inplace=True,
    )

    # åƒ¹é‡è¡ç”Ÿ
    df["æ”¶ç›¤_é–‹ç›¤"] = df["æ”¶ç›¤åƒ¹"] - df["é–‹ç›¤åƒ¹"]
    df["æ—¥æŒ¯å¹…"] = df["æœ€é«˜åƒ¹"] - df["æœ€ä½åƒ¹"]
    df["æ¼²è·Œå¹…_pct"] = (df["æ”¶ç›¤åƒ¹"] - df["æ”¶ç›¤åƒ¹"].shift(1)) / df["æ”¶ç›¤åƒ¹"].shift(1)
    df["é‡å¢ç‡_pct"] = (df["æˆäº¤é‡"] - df["æˆäº¤é‡"].shift(1)) / df["æˆäº¤é‡"].shift(1)

    df["æ˜¨æ”¶_tmp"] = df["æ”¶ç›¤åƒ¹"].shift(1)
    base_range = df["æ—¥æŒ¯å¹…"] / df["æ˜¨æ”¶_tmp"]
    sign = np.sign(df["æ”¶ç›¤åƒ¹"] - df["æ˜¨æ”¶_tmp"])
    df["æ—¥æŒ¯å¹…_æ˜¨æ”¶_pct"] = base_range * sign
    df.drop(columns=["æ˜¨æ”¶_tmp"], inplace=True)

    # å‡é‡ / å‡åƒ¹ / æ‰£æŠµ / ä¹–é›¢
    df["æˆäº¤é‡"] = pd.to_numeric(df["æˆäº¤é‡"], errors="coerce")
    for n in [5, 10, 20, 60]:
        df[f"{n}æ—¥å‡é‡"] = df["æˆäº¤é‡"].rolling(n).mean()
        df[f"{n}æ—¥å¹³å‡"] = df["æ”¶ç›¤åƒ¹"].rolling(n).mean()
        df[f"{n}æ—¥ä¸Šå‡å¹…åº¦"] = df[f"{n}æ—¥å¹³å‡"] - df[f"{n}æ—¥å¹³å‡"].shift(1)
        df[f"{n}æ—¥æ‰£æŠµå€¼"] = df["æ”¶ç›¤åƒ¹"].shift(n - 1)
        df[f"{n}æ—¥æ‰£æŠµå½±éŸ¿_pct"] = (df["æ”¶ç›¤åƒ¹"] - df[f"{n}æ—¥æ‰£æŠµå€¼"]) / df["æ”¶ç›¤åƒ¹"]
        df[f"{n}æ—¥ä¹–é›¢"] = (df["æ”¶ç›¤åƒ¹"] - df[f"{n}æ—¥å¹³å‡"]) / df[f"{n}æ—¥å¹³å‡"]

    # é‡‘é¡æ›ç®—
    df["ç¸½æˆäº¤é‡‘é¡_å„„"] = pd.to_numeric(df["ç¸½æˆäº¤é‡‘é¡_å„„"], errors="coerce") / 1e8

    # æ³•äººï¼ˆé˜²å‘†ï¼‰
    foreign = pd.to_numeric(_scol(df, "Foreign_Investor", default=np.nan), errors="coerce")
    itrust  = pd.to_numeric(_scol(df, "Investment_Trust", default=np.nan), errors="coerce")
    dealer  = _sum_cols_like(df, keywords=["Dealer"], default=0.0)

    total_net = pd.to_numeric(_scol(df, "total", default=np.nan), errors="coerce")
    if total_net.isna().all():
        total_net = foreign.fillna(0.0) + itrust.fillna(0.0) + pd.to_numeric(dealer, errors="coerce").fillna(0.0)

    df["æ³•äººç¸½è²·è¶…_å„„"] = total_net / 1e8
    df["è²·è¶…_å¤–è³‡_å„„"] = foreign / 1e8
    df["è²·è¶…_æŠ•ä¿¡_å„„"] = itrust / 1e8
    df["è²·è¶…_è‡ªç‡Ÿå•†_å„„"] = pd.to_numeric(dealer, errors="coerce").fillna(0.0) / 1e8

    # èè³‡ï¼ˆä»Šæ—¥é¤˜é¡ï¼šä»Ÿå…ƒï¼‰
    df["èè³‡é¤˜é¡_å„„"] = pd.to_numeric(_scol(df, "ä»Šæ—¥é¤˜é¡", default=np.nan), errors="coerce") * 1000 / 1e8
    df["è²·è¶…_èè³‡_å„„"] = df["èè³‡é¤˜é¡_å„„"] - df["èè³‡é¤˜é¡_å„„"].shift(1)

    # è³‡é‡‘èµ°å‘
    df["è³‡é‡‘èµ°å‘"] = df["æ”¶ç›¤_é–‹ç›¤"] - (df["æ³•äººç¸½è²·è¶…_å„„"] + df["è²·è¶…_èè³‡_å„„"])
    df["è³‡é‡‘èµ°å‘åˆ¤è®€"] = df["è³‡é‡‘èµ°å‘"].apply(lambda x: None if pd.isna(x) else ("åé‡å¤§å‹è‚¡" if x > 0 else ("åé‡å°å‹è‚¡" if x < 0 else None)))

    # å¯¦é«” / ä¸Šå½± / ä¸‹å½±
    rng = (df["æœ€é«˜åƒ¹"] - df["æœ€ä½åƒ¹"]).replace(0, np.nan)
    df["å¯¦é«”_pct"] = (df["æ”¶ç›¤åƒ¹"] - df["é–‹ç›¤åƒ¹"]).abs() / rng
    df["ä¸Šå½±_pct"] = (df["æœ€é«˜åƒ¹"] - np.maximum(df["é–‹ç›¤åƒ¹"], df["æ”¶ç›¤åƒ¹"])) / rng
    df["ä¸‹å½±_pct"] = (np.minimum(df["é–‹ç›¤åƒ¹"], df["æ”¶ç›¤åƒ¹"]) - df["æœ€ä½åƒ¹"]) / rng

    # K ç·šå‹æ…‹
    df["Kç·šå‹æ…‹"] = df.apply(_classify_k_type_row, axis=1)

    # è·³ç©ºç¼ºå£
    df["æ˜¨é«˜"] = df["æœ€é«˜åƒ¹"].shift(1)
    df["æ˜¨ä½"] = df["æœ€ä½åƒ¹"].shift(1)
    df["è·³ç©ºç‹€æ…‹"] = np.select(
        [df["æœ€ä½åƒ¹"] > df["æ˜¨é«˜"], df["æœ€é«˜åƒ¹"] < df["æ˜¨ä½"]],
        ["ä¸Šè·³ç©º", "ä¸‹è·³ç©º"],
        default="ç„¡è·³ç©º",
    )
    is_red = df["æ”¶ç›¤åƒ¹"] > df["é–‹ç›¤åƒ¹"]
    df["ä»Šä¸Šç·£"] = np.where(is_red, df["æ”¶ç›¤åƒ¹"], df["é–‹ç›¤åƒ¹"])
    df["ä»Šä¸‹ç·£"] = np.where(is_red, df["é–‹ç›¤åƒ¹"], df["æ”¶ç›¤åƒ¹"])
    df["æ˜¨ä¸Šç·£"] = df["ä»Šä¸Šç·£"].shift(1)
    df["æ˜¨ä¸‹ç·£"] = df["ä»Šä¸‹ç·£"].shift(1)

    df["è·³ç©ºç¼ºå£"] = np.select(
        [df["è·³ç©ºç‹€æ…‹"] == "ä¸Šè·³ç©º", df["è·³ç©ºç‹€æ…‹"] == "ä¸‹è·³ç©º"],
        [df["ä»Šä¸‹ç·£"] - df["æ˜¨ä¸Šç·£"], df["ä»Šä¸Šç·£"] - df["æ˜¨ä¸‹ç·£"]],
        default=None,
    )

    # é‡èƒ½æœ€å¤§é‡ï¼ˆ5/10/20/60ï¼‰
    vols = df["æˆäº¤é‡"].to_numpy()
    dates = pd.to_datetime(df["æ—¥æœŸ"]).dt.strftime("%Y-%m-%d").to_numpy()
    for n in [5, 10, 20, 60]:
        vmax_list, vdate_list = [], []
        for i in range(len(df)):
            if i + 1 < n:
                vmax_list.append(np.nan)
                vdate_list.append(np.nan)
                continue
            window_vol = vols[i + 1 - n : i + 1]
            window_date = dates[i + 1 - n : i + 1]
            idx = int(np.argmax(window_vol))
            vmax_list.append(window_vol[idx])
            vdate_list.append(window_date[idx])
        df[f"{n}æ—¥æœ€å¤§é‡"] = vmax_list
        df[f"{n}æ—¥æœ€å¤§é‡_æ—¥æœŸ"] = vdate_list

    return df


# é€™è£¡æ˜¯ã€Œæ¬„ä½ -> å¦‚ä½•å¾å·²ç®—å¥½çš„ df å–å€¼ã€çš„ registry
# ä½ ä¹‹å¾Œè¦è£œæ–°æ¬„ä½ï¼Œåªè¦åŠ ä¸€å€‹ key å³å¯
FIELD_REGISTRY = {
    # åƒ¹é‡
    "æ”¶ç›¤_é–‹ç›¤": lambda d: d["æ”¶ç›¤_é–‹ç›¤"],
    "æ—¥æŒ¯å¹…": lambda d: d["æ—¥æŒ¯å¹…"],
    "æ¼²è·Œå¹…_pct": lambda d: d["æ¼²è·Œå¹…_pct"],
    "é‡å¢ç‡_pct": lambda d: d["é‡å¢ç‡_pct"],
    "æ—¥æŒ¯å¹…_æ˜¨æ”¶_pct": lambda d: d["æ—¥æŒ¯å¹…_æ˜¨æ”¶_pct"],

    # å‡é‡/å‡åƒ¹/æ‰£æŠµ/ä¹–é›¢/ä¸Šå‡å¹…åº¦
    "5æ—¥å‡é‡": lambda d: d["5æ—¥å‡é‡"],
    "10æ—¥å‡é‡": lambda d: d["10æ—¥å‡é‡"],
    "20æ—¥å‡é‡": lambda d: d["20æ—¥å‡é‡"],
    "60æ—¥å‡é‡": lambda d: d["60æ—¥å‡é‡"],

    "5æ—¥å¹³å‡": lambda d: d["5æ—¥å¹³å‡"],
    "10æ—¥å¹³å‡": lambda d: d["10æ—¥å¹³å‡"],
    "20æ—¥å¹³å‡": lambda d: d["20æ—¥å¹³å‡"],
    "60æ—¥å¹³å‡": lambda d: d["60æ—¥å¹³å‡"],

    "5æ—¥ä¸Šå‡å¹…åº¦": lambda d: d["5æ—¥ä¸Šå‡å¹…åº¦"],
    "10æ—¥ä¸Šå‡å¹…åº¦": lambda d: d["10æ—¥ä¸Šå‡å¹…åº¦"],
    "20æ—¥ä¸Šå‡å¹…åº¦": lambda d: d["20æ—¥ä¸Šå‡å¹…åº¦"],
    "60æ—¥ä¸Šå‡å¹…åº¦": lambda d: d["60æ—¥ä¸Šå‡å¹…åº¦"],

    "5æ—¥æ‰£æŠµå€¼": lambda d: d["5æ—¥æ‰£æŠµå€¼"],
    "10æ—¥æ‰£æŠµå€¼": lambda d: d["10æ—¥æ‰£æŠµå€¼"],
    "20æ—¥æ‰£æŠµå€¼": lambda d: d["20æ—¥æ‰£æŠµå€¼"],
    "60æ—¥æ‰£æŠµå€¼": lambda d: d["60æ—¥æ‰£æŠµå€¼"],

    "5æ—¥æ‰£æŠµå½±éŸ¿_pct": lambda d: d["5æ—¥æ‰£æŠµå½±éŸ¿_pct"],
    "10æ—¥æ‰£æŠµå½±éŸ¿_pct": lambda d: d["10æ—¥æ‰£æŠµå½±éŸ¿_pct"],
    "20æ—¥æ‰£æŠµå½±éŸ¿_pct": lambda d: d["20æ—¥æ‰£æŠµå½±éŸ¿_pct"],
    "60æ—¥æ‰£æŠµå½±éŸ¿_pct": lambda d: d["60æ—¥æ‰£æŠµå½±éŸ¿_pct"],

    "5æ—¥ä¹–é›¢": lambda d: d["5æ—¥ä¹–é›¢"],
    "10æ—¥ä¹–é›¢": lambda d: d["10æ—¥ä¹–é›¢"],
    "20æ—¥ä¹–é›¢": lambda d: d["20æ—¥ä¹–é›¢"],
    "60æ—¥ä¹–é›¢": lambda d: d["60æ—¥ä¹–é›¢"],

    # é‡‘é¡/æ³•äºº/èè³‡/è³‡é‡‘èµ°å‘
    "ç¸½æˆäº¤é‡‘é¡_å„„": lambda d: d["ç¸½æˆäº¤é‡‘é¡_å„„"],
    "æ³•äººç¸½è²·è¶…_å„„": lambda d: d["æ³•äººç¸½è²·è¶…_å„„"],
    "è²·è¶…_å¤–è³‡_å„„": lambda d: d["è²·è¶…_å¤–è³‡_å„„"],
    "è²·è¶…_æŠ•ä¿¡_å„„": lambda d: d["è²·è¶…_æŠ•ä¿¡_å„„"],
    "è²·è¶…_è‡ªç‡Ÿå•†_å„„": lambda d: d["è²·è¶…_è‡ªç‡Ÿå•†_å„„"],
    "è²·è¶…_èè³‡_å„„": lambda d: d["è²·è¶…_èè³‡_å„„"],
    "è³‡é‡‘èµ°å‘": lambda d: d["è³‡é‡‘èµ°å‘"],
    "è³‡é‡‘èµ°å‘åˆ¤è®€": lambda d: d["è³‡é‡‘èµ°å‘åˆ¤è®€"],

    # K ç·š/è·³ç©º/å½±ç·š
    "å¯¦é«”_pct": lambda d: d["å¯¦é«”_pct"],
    "ä¸Šå½±_pct": lambda d: d["ä¸Šå½±_pct"],
    "ä¸‹å½±_pct": lambda d: d["ä¸‹å½±_pct"],
    "Kç·šå‹æ…‹": lambda d: d["Kç·šå‹æ…‹"],
    "è·³ç©ºç¼ºå£": lambda d: d["è·³ç©ºç¼ºå£"],

    # é‡èƒ½æœ€å¤§
    "5æ—¥æœ€å¤§é‡": lambda d: d["5æ—¥æœ€å¤§é‡"],
    "5æ—¥æœ€å¤§é‡_æ—¥æœŸ": lambda d: d["5æ—¥æœ€å¤§é‡_æ—¥æœŸ"],
    "10æ—¥æœ€å¤§é‡": lambda d: d["10æ—¥æœ€å¤§é‡"],
    "10æ—¥æœ€å¤§é‡_æ—¥æœŸ": lambda d: d["10æ—¥æœ€å¤§é‡_æ—¥æœŸ"],
    "20æ—¥æœ€å¤§é‡": lambda d: d["20æ—¥æœ€å¤§é‡"],
    "20æ—¥æœ€å¤§é‡_æ—¥æœŸ": lambda d: d["20æ—¥æœ€å¤§é‡_æ—¥æœŸ"],
    "60æ—¥æœ€å¤§é‡": lambda d: d["60æ—¥æœ€å¤§é‡"],
    "60æ—¥æœ€å¤§é‡_æ—¥æœŸ": lambda d: d["60æ—¥æœ€å¤§é‡_æ—¥æœŸ"],
}


# =========================================================
# 3) DB å›å¯«ï¼šåªæ›´æ–°æŒ‡å®šæ¬„ä½ï¼ˆä¸å‹•å…¶ä»–æ¬„ï¼‰
#    - ä½ åªè¦æŠŠ db.execute_sql / db.executemany å°ä¸Šä½ çš„å¯¦ä½œ
# =========================================================
def _update_fields_to_db(db, table, key_cols, df_patch, fields):
    """
    df_patch: è‡³å°‘åŒ…å« key_cols + fields
    key_cols é è¨­ç”¨ ["è‚¡ç¥¨ä»£è™Ÿ","æ—¥æœŸ"]ï¼ˆæ—¥æœŸå»ºè­°ç”¨ YYYY-MM-DDï¼‰
    """
    if df_patch.empty:
        return 0

    # çµ±ä¸€æ—¥æœŸæ ¼å¼
    if "æ—¥æœŸ" in df_patch.columns:
        df_patch = df_patch.copy()
        df_patch["æ—¥æœŸ"] = pd.to_datetime(df_patch["æ—¥æœŸ"]).dt.strftime("%Y-%m-%d")

    set_clause = ", ".join([f'"{c}" = ?' for c in fields])
    where_clause = " AND ".join([f'"{k}" = ?' for k in key_cols])

    sql = f'UPDATE "{table}" SET {set_clause} WHERE {where_clause}'

    params = []
    for _, r in df_patch.iterrows():
        row_vals = [r.get(c, None) for c in fields] + [r.get(k, None) for k in key_cols]
        params.append(row_vals)

    # ä½ å¦‚æœæ²’æœ‰ executemanyï¼Œå°± loop execute_sql ä¹Ÿè¡Œï¼ˆæ…¢ä¸€é»ï¼‰
    if hasattr(db, "executemany"):
        db.executemany(sql, params)
    else:
        for p in params:
            db.execute_sql(sql, p)

    return len(params)


# === helper: å–æ¬„ä½æˆã€Œæ•´æ¬„ Seriesã€ï¼Œä¸å­˜åœ¨å°±å› 0ï¼ˆæˆ– NaNï¼‰ ===
def _scol(df_, col, default=0.0):
    if col in df_.columns:
        s = df_[col]
        # ä¿éšªï¼šæœ‰äººæŠŠåŒåæ¬„ä½ merge å£æ‰è®Š scalar
        if isinstance(s, pd.Series):
            return s
        return pd.Series([s] * len(df_), index=df_.index)
    return pd.Series([default] * len(df_), index=df_.index)

# === helper: å¤šå€‹å€™é¸æ¬„ä½åŠ ç¸½ï¼ˆå­˜åœ¨æ‰ç®—ï¼‰ ===
def _sum_cols(df_, cols, default=0.0):
    out = pd.Series([0.0] * len(df_), index=df_.index, dtype="float64")
    hit = False
    for c in cols:
        if c in df_.columns:
            out = out + pd.to_numeric(_scol(df_, c, default=0.0), errors="coerce").fillna(0.0)
            hit = True
    if not hit:
        return pd.Series([default] * len(df_), index=df_.index, dtype="float64")
    return out

# === helper: æ‰¾å‡º df å…§æ‰€æœ‰åŒ…å«æŸäº›é—œéµå­—çš„æ¬„ä½ä¸¦åŠ ç¸½ï¼ˆfor Dealer* é€™ç¨®ä¸ç©©å®šæ¬„åï¼‰ ===
def _sum_cols_like(df_, keywords, default=0.0):
    cols = []
    for c in df_.columns:
        cs = str(c)
        if any(k in cs for k in keywords):
            cols.append(c)
    if not cols:
        return pd.Series([default] * len(df_), index=df_.index, dtype="float64")
    return _sum_cols(df_, cols, default=default)

# === 9) K ç·šå‹æ…‹ ===
def classify_k_type(r):
    body = r["å¯¦é«”_pct"]
    upper = r["ä¸Šå½±_pct"]
    lower = r["ä¸‹å½±_pct"]
    open_p = r["é–‹ç›¤åƒ¹"]
    close_p = r["æ”¶ç›¤åƒ¹"]

    if pd.isna(body) or pd.isna(upper) or pd.isna(lower):
        return None

    if abs(close_p - open_p) < 1e-6 or body < 0.05:
        return "â¬œ åå­—ç·š"

    is_red = close_p > open_p
    color = "ğŸŸ¥" if is_red else "ğŸŸ©"

    if lower > 0.5 and body < 0.3:
        return f"{color} éŒ˜å­ç·š"
    if upper > 0.5 and body < 0.3:
        return f"{color} æµæ˜Ÿç·š"
    if body > 0.6:
        return f"{color} é•·ç´…K" if is_red else f"{color} é•·é»‘K"
    return f"{color} ä¸­å¯¦é«”K"

def update_is_complete():
    table = "stock_report_daily"

    # é è¨­ä¸æª¢æŸ¥é€™äº›æ¬„ä½
    exclude_cols = {
        "is_complete",
        "id",
        "è·³ç©ºç¼ºå£",
        "created_at",
        "updated_at"
    }

    # å–å¾—æ‰€æœ‰æ¬„ä½
    cols_df = db.query_to_df(f"PRAGMA table_info('{table}');")
    all_cols = cols_df["name"].tolist()

    # éæ¿¾ä¸æª¢æŸ¥çš„æ¬„ä½
    check_cols = [c for c in all_cols if c not in exclude_cols]

    if not check_cols:
        print("âš  æ²’æœ‰å¯æª¢æŸ¥æ¬„ä½ï¼Œè·³éæ›´æ–°ã€‚")
        return

    # å®‰å…¨åŒ…è£æ¬„ä½åæˆ "æ¬„ä½"
    def q(name: str) -> str:
        return '"' + name.replace('"', '""') + '"'

    # å»ºç«‹ NULL åˆ¤æ–·æ¢ä»¶
    null_conditions = " OR ".join([f"{q(c)} IS NULL" for c in check_cols])

    # æœ€çµ‚ SQL
    sql = f"""
    UPDATE {q(table)}
    SET {q("is_complete")} = CASE
        WHEN {null_conditions} THEN 0
        ELSE 1
    END;
    """

    print("åŸ·è¡Œ SQL ä¸­ ...")
    ok = db.execute_sql(sql)
    print("æ›´æ–°å®Œæˆ âœ”" if ok else "æ›´æ–°å¤±æ•— âŒ")
    

TABLE = "stock_report_daily"
COLUMNS = [
    "æ—¥æœŸ","è‚¡ç¥¨ä»£è™Ÿ",
    "é–‹ç›¤åƒ¹","æ”¶ç›¤åƒ¹","æ”¶ç›¤_é–‹ç›¤","æœ€é«˜åƒ¹","æœ€ä½åƒ¹","æ—¥æŒ¯å¹…","æ¼²è·Œå¹…_pct","æ—¥æŒ¯å¹…_æ˜¨æ”¶_pct",
    "æˆäº¤é‡","é‡å¢ç‡_pct",
    "5æ—¥å‡é‡","5æ—¥æœ€å¤§é‡_æ—¥æœŸ","5æ—¥æœ€å¤§é‡",
    "10æ—¥å‡é‡","10æ—¥æœ€å¤§é‡_æ—¥æœŸ","10æ—¥æœ€å¤§é‡",
    "20æ—¥å‡é‡","20æ—¥æœ€å¤§é‡_æ—¥æœŸ","20æ—¥æœ€å¤§é‡",
    "60æ—¥å‡é‡","60æ—¥æœ€å¤§é‡_æ—¥æœŸ","60æ—¥æœ€å¤§é‡",
    "å¯¦é«”_pct","ä¸Šå½±_pct","ä¸‹å½±_pct","Kç·šå‹æ…‹","è·³ç©ºç¼ºå£",
    "5æ—¥å¹³å‡","10æ—¥å¹³å‡","20æ—¥å¹³å‡","60æ—¥å¹³å‡",
    "5æ—¥ä¸Šå‡å¹…åº¦","10æ—¥ä¸Šå‡å¹…åº¦","20æ—¥ä¸Šå‡å¹…åº¦","60æ—¥ä¸Šå‡å¹…åº¦",
    "5æ—¥æ‰£æŠµå€¼","10æ—¥æ‰£æŠµå€¼","20æ—¥æ‰£æŠµå€¼","60æ—¥æ‰£æŠµå€¼",
    "5æ—¥æ‰£æŠµå½±éŸ¿_pct","10æ—¥æ‰£æŠµå½±éŸ¿_pct","20æ—¥æ‰£æŠµå½±éŸ¿_pct","60æ—¥æ‰£æŠµå½±éŸ¿_pct",
    "5æ—¥ä¹–é›¢","10æ—¥ä¹–é›¢","20æ—¥ä¹–é›¢","60æ—¥ä¹–é›¢",
    "ç¸½æˆäº¤é‡‘é¡_å„„","æ³•äººç¸½è²·è¶…_å„„","è²·è¶…_å¤–è³‡_å„„","è²·è¶…_æŠ•ä¿¡_å„„","è²·è¶…_è‡ªç‡Ÿå•†_å„„","è²·è¶…_èè³‡_å„„",
    "è³‡é‡‘èµ°å‘","è³‡é‡‘èµ°å‘åˆ¤è®€",
    "is_complete",
]

# ======================================
# UPSERT
# ======================================
def upsert(df: pd.DataFrame, stock_id: str):
    if df.empty:
        print("âš  df empty, skip")
        return

    df = df.copy()
    df["è‚¡ç¥¨ä»£è™Ÿ"] = stock_id
    df["æ—¥æœŸ"] = pd.to_datetime(df["æ—¥æœŸ"]).dt.strftime("%Y-%m-%d")

    # --- is_completeï¼šå…ˆé è¨­ 0, å¾Œé¢è¦†å¯« ---
    df["is_complete"] = 0

    # æ¬„ä½å°é½Š SQLite æ¨™æº–æ¬„ä½
    df = df[[c for c in df.columns if c in COLUMNS]]
    for c in COLUMNS:
        if c not in df.columns:
            df[c] = np.nan
    df = df[COLUMNS]

    # æ ¹æ“šã€Œæ‰€æœ‰æ•¸å€¼æ¬„ä½ã€æ˜¯å¦éƒ½æœ‰å€¼ä¾†æ±ºå®š is_complete
    text_cols = [
        "æ—¥æœŸ","è‚¡ç¥¨ä»£è™Ÿ","Kç·šå‹æ…‹","å‡ç·šæ–¹å‘","å‡ç·šæ’åˆ—",
        "å‡ç·šç‹€æ…‹","è¶¨å‹¢å¼·åº¦èªªæ˜","è³‡é‡‘èµ°å‘åˆ¤è®€"
    ]
    numeric_cols = [c for c in COLUMNS if c not in text_cols + ["is_complete"]]
    # å¦‚æœæœ‰ä»»ä½•æ•¸å€¼æ¬„ä½æ˜¯ NaNï¼Œå°±è¦–ç‚ºæœªå®Œæˆ
    df["is_complete"] = (~df[numeric_cols].isna().any(axis=1)).astype(int)

    # SQL çµ„èµ·ä¾†
    col_sql = ",".join([f'"{c}"' for c in COLUMNS])
    ph = ",".join(["?"] * len(COLUMNS))
    update_sql = ",".join([f'"{c}" = excluded."{c}"' for c in COLUMNS if c not in ("æ—¥æœŸ", "è‚¡ç¥¨ä»£è™Ÿ")])

    sql = f"""
    INSERT INTO "{TABLE}" ({col_sql})
    VALUES ({ph})
    ON CONFLICT("è‚¡ç¥¨ä»£è™Ÿ","æ—¥æœŸ") DO UPDATE SET
        {update_sql}
    WHERE "{TABLE}".is_complete = 0
       OR excluded.is_complete = 1;
    """

    rows = list(df.itertuples(index=False, name=None))

    ok = db.execute_sql(sql, rows)
    if ok:
        print(f"âœ” DB å¯«å…¥æˆåŠŸ: {len(df)} rows, stock={stock_id}")
    else:
        print("âŒ DB å¯«å…¥å¤±æ•—ï¼ˆè«‹çœ‹ä¸Šæ–¹ SQLite Errorï¼‰")