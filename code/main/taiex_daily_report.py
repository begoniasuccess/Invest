# taiEX_daily_report_final.py
import os
import sys
import pandas as pd
import numpy as np
from FinMind.data import DataLoader
from datetime import datetime
from dateutil.relativedelta import relativedelta
from module import twse

# === åŸºæœ¬è¨­å®š ===
token = "eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJkYXRlIjoiMjAyNS0xMC0wNCAxMzoxMjo1NyIsInVzZXJfaWQiOiJueWN1bGFiNjE1IiwiaXAiOiI0Mi43My41NS4xMDYifQ.YMhmYo6sx7_Z0WZwPbNcjDi8gPvt-a6bIx6XHeax4LM"
api = DataLoader()
api.login_by_token(api_token=token)

stockId = "TAIEX"
anaMonths = 2
forceRerun = False
forceReAna = True
if forceRerun:
    forceReAna = True

# === æ—¥æœŸèˆ‡è·¯å¾‘ ===
eDt = datetime.today()
sDt = eDt - relativedelta(months=anaMonths)
print(sDt.strftime("%Y%m%d"), eDt.strftime("%Y%m%d"))

anaRootDir = f"../Data/ana/anaKplot/{stockId}/{sDt.strftime('%Y%m')}"
os.makedirs(anaRootDir, exist_ok=True)

rawDir = f"../Data/finMind/taiwan_stock_daily_adj/{stockId}/{sDt.strftime('%Y%m')}"
os.makedirs(rawDir, exist_ok=True)
rawFile = f"{rawDir}/{sDt.strftime('%Y%m%d')}_{eDt.strftime('%Y%m%d')}.csv"

# === åŒ¯å…¥æˆ–æŠ“å–æ—¥è³‡æ–™ ===
if not forceRerun and os.path.exists(rawFile):
    print(f"æ¯æ—¥åƒ¹é‡è³‡æ–™å·²å­˜åœ¨ï¼š{rawFile}")
    df = pd.read_csv(rawFile)
else:
    df = api.taiwan_stock_daily_adj(
        stock_id=stockId,
        start_date=sDt.strftime("%Y-%m-%d"),
        end_date=eDt.strftime("%Y-%m-%d"),
    )
    df.to_csv(rawFile, index=False, encoding="utf-8-sig")

df["date"] = pd.to_datetime(df["date"])
df = df.sort_values("date").reset_index(drop=True)

# === ä¸‰å¤§æ³•äºº ===
if stockId in ["TAIEX", "TPEx"]:
    miiDir = f"../Data/finMind/taiwan_stock_institutional_investors/all/{sDt.strftime('%Y%m')}"
else:
    miiDir = f"../Data/finMind/taiwan_stock_institutional_investors/{stockId}/{sDt.strftime('%Y%m')}"
os.makedirs(miiDir, exist_ok=True)
miiFile = f"{miiDir}/{sDt.strftime('%Y%m%d')}_{eDt.strftime('%Y%m%d')}-3mii.csv"

if not forceRerun and os.path.exists(miiFile):
    df_3mii = pd.read_csv(miiFile)
else:
    if stockId in ["TAIEX", "TPEx"]:
        df_3mii = api.taiwan_stock_institutional_investors_total(
            start_date=sDt.strftime("%Y-%m-%d"),
            end_date=eDt.strftime("%Y-%m-%d"),
        )
    else:
        df_3mii = api.taiwan_stock_institutional_investors(
            stock_id=stockId,
            start_date=sDt.strftime("%Y-%m-%d"),
            end_date=eDt.strftime("%Y-%m-%d"),
        )
    df_3mii.to_csv(miiFile, index=False, encoding="utf-8-sig")

# === èè³‡é¤˜é¡ï¼ˆtwse è‡ªè£½ï¼‰ ===
df_margin = twse.get_margin_trading(sDt, eDt)
df_margin = df_margin[df_margin["é …ç›®"] == "èè³‡é‡‘é¡(ä»Ÿå…ƒ)"].copy()
df_margin["æ—¥æœŸ"] = pd.to_datetime(df_margin["æ—¥æœŸ"], format="%Y%m%d")

# === åˆªæ‰ä¸éœ€è¦æ¬„ä½ä¸¦åŠ åŸºç¤è¡ç”Ÿ ===
df = df.drop(columns=["spread", "Trading_turnover"], errors="ignore")
df["close-open"] = df["close"] - df["open"]
df["max-min"] = df["max"] - df["min"]
df["Volume_Change"] = (df["Trading_Volume"] - df["Trading_Volume"].shift(1)) / df["Trading_Volume"].shift(1)

# å‡é‡èˆ‡å‡ç·šã€ä¹–é›¢
for n in [5, 10, 20]:
    df[f"{n}æ—¥å‡é‡"] = df["Trading_Volume"].rolling(window=n).mean()
    df[f"{n}MA"] = df["close"].rolling(window=n).mean()
    df[f"{n}_Devi"] = (df["close"] - df[f"{n}MA"]) / df[f"{n}MA"]

# === åˆä½µæ³•äºº ===
if df_3mii.empty:
    df_3mii = pd.DataFrame(columns=["buy", "sell", "date", "name"])
df_3mii["net_buy"] = df_3mii["buy"] - df_3mii["sell"]
df_3mii["date"] = pd.to_datetime(df_3mii["date"])
map_name = {
    "Foreign_Investor": "è²·è¶…-å¤–è³‡",
    "Investment_Trust": "è²·è¶…-æŠ•ä¿¡",
    "Dealer_self": "è²·è¶…-è‡ªç‡Ÿå•†(è‡ªè¡Œè²·è³£)",
    "Dealer_Hedging": "è²·è¶…-è‡ªç‡Ÿå•†(é¿éšª)",
    "Foreign_Dealer_Self": "è²·è¶…-å¤–è³‡è‡ªç‡Ÿå•†",
    "total": "æ³•äººç¸½è²·è¶…",
}
df_3mii["col_name"] = df_3mii["name"].map(map_name)
df_3mii_wide = df_3mii.pivot(index="date", columns="col_name", values="net_buy").reset_index()
df_merged = df.merge(df_3mii_wide, on="date", how="left")

# === åˆä½µèè³‡ ===
df_merged = df_merged.merge(df_margin[["æ—¥æœŸ", "ä»Šæ—¥é¤˜é¡"]], left_on="date", right_on="æ—¥æœŸ", how="left")
df_merged.drop(columns=["æ—¥æœŸ"], inplace=True)
df_merged["èè³‡é¤˜é¡(å„„)"] = pd.to_numeric(df_merged["ä»Šæ—¥é¤˜é¡"], errors="coerce") * 1000 / 1e8
df_merged["èè³‡å¢æ¸›(å„„)"] = df_merged["èè³‡é¤˜é¡(å„„)"] - df_merged["èè³‡é¤˜é¡(å„„)"].shift(1)

# === è³‡é‡‘èµ°å‘ï¼ˆä»ç”¨åŸæœ¬è¨ˆç®—åŸºç¤ï¼‰ ===
df_merged["è³‡é‡‘èµ°å‘"] = df_merged["close-open"] - (
    (pd.to_numeric(df_merged.get("æ³•äººç¸½è²·è¶…"), errors="coerce") / 1e8) + df_merged["èè³‡å¢æ¸›(å„„)"]
)
df_merged["è³‡é‡‘èµ°å‘åˆ¤è®€"] = df_merged["è³‡é‡‘èµ°å‘"].apply(
    lambda x: "åé‡å¤§å‹è‚¡(å¤š)" if x > 0 else ("åé‡å°å‹è‚¡(ç©º)" if x < 0 else None)
)

# === è½‰ä¸­æ–‡æ¬„ä½ ===
rename_dict = {
    "date": "æ—¥æœŸ",
    "stock_id": "è‚¡ç¥¨ä»£è™Ÿ",
    "Trading_Volume": "æˆäº¤é‡",
    "Volume_Change": "é‡å¢ç‡(%)",
    "Trading_money": "ç¸½æˆäº¤é‡‘é¡(å„„)",
    "open": "é–‹ç›¤åƒ¹",
    "max": "æœ€é«˜åƒ¹",
    "min": "æœ€ä½åƒ¹",
    "close": "æ”¶ç›¤åƒ¹",
    "close-open": "æ”¶ç›¤-é–‹ç›¤",
    "max-min": "æ—¥æŒ¯å¹…",
    "5MA": "5æ—¥å¹³å‡",
    "10MA": "10æ—¥å¹³å‡",
    "20MA": "20æ—¥å¹³å‡",
    "5_Devi": "5æ—¥ä¹–é›¢",
    "10_Devi": "10æ—¥ä¹–é›¢",
    "20_Devi": "20æ—¥ä¹–é›¢",
    "æ³•äººç¸½è²·è¶…": "æ³•äººç¸½è²·è¶…(å„„)",
    "è²·è¶…-å¤–è³‡": "è²·è¶…-å¤–è³‡(å„„)",
    "è²·è¶…-æŠ•ä¿¡": "è²·è¶…-æŠ•ä¿¡(å„„)",
    "èè³‡å¢æ¸›(å„„)": "è²·è¶…-èè³‡(å„„)",
}
new_df = df_merged.rename(columns=rename_dict).copy()

# === é‡‘é¡å–®ä½çµ±ä¸€æ›ç®—æˆã€Œå„„ã€ ===
for col in ["ç¸½æˆäº¤é‡‘é¡(å„„)", "æ³•äººç¸½è²·è¶…(å„„)", "è²·è¶…-å¤–è³‡(å„„)", "è²·è¶…-æŠ•ä¿¡(å„„)",
            "è²·è¶…-è‡ªç‡Ÿå•†(è‡ªè¡Œè²·è³£)", "è²·è¶…-è‡ªç‡Ÿå•†(é¿éšª)", "è²·è¶…-å¤–è³‡è‡ªç‡Ÿå•†"]:
    if col in new_df.columns:
        new_df[col] = pd.to_numeric(new_df[col], errors="coerce") / 1e8

# è‡ªç‡Ÿå•†(å„„) = å¤–è³‡è‡ªç‡Ÿå•† + è‡ªç‡Ÿ(è‡ªè¡Œè²·è³£) + è‡ªç‡Ÿ(é¿éšª)
new_df["è²·è¶…-è‡ªç‡Ÿå•†(å„„)"] = (
    pd.to_numeric(new_df.get("è²·è¶…-å¤–è³‡è‡ªç‡Ÿå•†"), errors="coerce").fillna(0) +
    pd.to_numeric(new_df.get("è²·è¶…-è‡ªç‡Ÿå•†(è‡ªè¡Œè²·è³£)"), errors="coerce").fillna(0) +
    pd.to_numeric(new_df.get("è²·è¶…-è‡ªç‡Ÿå•†(é¿éšª)"), errors="coerce").fillna(0)
)

# === åƒ¹/ç·šå‹è¡ç”Ÿ ===
new_df["æ¼²è·Œå¹…(%)"] = (new_df["æ”¶ç›¤åƒ¹"] - new_df["æ”¶ç›¤åƒ¹"].shift(1)) / new_df["æ”¶ç›¤åƒ¹"].shift(1)
new_df["å¯¦é«”(æ¼²è·Œç‡)"] = (new_df["æ”¶ç›¤åƒ¹"] - new_df["é–‹ç›¤åƒ¹"]) / new_df["é–‹ç›¤åƒ¹"]

# ä¸Šå½±&ä¸‹å½±ï¼ˆä¾ç´…é»‘Kï¼‰
is_red = new_df["æ”¶ç›¤åƒ¹"] >= new_df["é–‹ç›¤åƒ¹"]
new_df["ä¸Šå½±(%)"] = np.where(
    is_red,
    (new_df["æœ€é«˜åƒ¹"] - new_df["æ”¶ç›¤åƒ¹"]) / new_df["æœ€é«˜åƒ¹"],
    (new_df["æœ€é«˜åƒ¹"] - new_df["é–‹ç›¤åƒ¹"]) / new_df["æœ€é«˜åƒ¹"]
)
new_df["ä¸‹å½±(%)"] = np.where(
    is_red,
    (new_df["é–‹ç›¤åƒ¹"] - new_df["æœ€ä½åƒ¹"]) / new_df["æœ€ä½åƒ¹"],
    (new_df["æ”¶ç›¤åƒ¹"] - new_df["æœ€ä½åƒ¹"]) / new_df["æœ€ä½åƒ¹"]
)
# å½±ç·š/å¯¦é«”
body_up = (new_df["æ”¶ç›¤åƒ¹"] - new_df["é–‹ç›¤åƒ¹"]).replace(0, np.nan)
body_dn = (new_df["é–‹ç›¤åƒ¹"] - new_df["æ”¶ç›¤åƒ¹"]).replace(0, np.nan)
new_df["ä¸Šå½±/å¯¦é«”"] = np.where(is_red,
    (new_df["æœ€é«˜åƒ¹"] - new_df["æ”¶ç›¤åƒ¹"]) / body_up,
    (new_df["æœ€é«˜åƒ¹"] - new_df["é–‹ç›¤åƒ¹"]) / body_dn
)
new_df["ä¸‹å½±/å¯¦é«”"] = np.where(is_red,
    (new_df["é–‹ç›¤åƒ¹"] - new_df["æœ€ä½åƒ¹"]) / body_up,
    (new_df["æ”¶ç›¤åƒ¹"] - new_df["æœ€ä½åƒ¹"]) / body_dn
)

# è·³ç©ºç¼ºå£ï¼ˆä»¥Kæ£’ã€Œå¯¦é«”ã€ä¸Š/ä¸‹ç·£è¨ˆï¼‰
new_df["æ˜¨é«˜"] = new_df["æœ€é«˜åƒ¹"].shift(1)
new_df["æ˜¨ä½"] = new_df["æœ€ä½åƒ¹"].shift(1)
# ä¾å¯¦é«”ç¯„åœ
today_top = np.where(is_red, new_df["æ”¶ç›¤åƒ¹"], new_df["é–‹ç›¤åƒ¹"])
today_bot = np.where(is_red, new_df["é–‹ç›¤åƒ¹"], new_df["æ”¶ç›¤åƒ¹"])
yest_is_red = (new_df["æ”¶ç›¤åƒ¹"].shift(1) >= new_df["é–‹ç›¤åƒ¹"].shift(1))
yest_top = np.where(yest_is_red, new_df["æ”¶ç›¤åƒ¹"].shift(1), new_df["é–‹ç›¤åƒ¹"].shift(1))
yest_bot = np.where(yest_is_red, new_df["é–‹ç›¤åƒ¹"].shift(1), new_df["æ”¶ç›¤åƒ¹"].shift(1))

cond_up_gap = (new_df["æœ€ä½åƒ¹"] > new_df["æ˜¨é«˜"])
cond_dn_gap = (new_df["æœ€é«˜åƒ¹"] < new_df["æ˜¨ä½"])
new_df["è·³ç©ºç¼ºå£"] = np.select(
    [cond_up_gap, cond_dn_gap],
    [today_bot - yest_top, today_top - yest_bot],
    default=np.nan
)

# === å‡ç·šä¸­æ–‡æ¬„ä½ï¼ˆå¾è‹±åè½‰ä¸­æ–‡ï¼‰ ===
new_df["5æ—¥å¹³å‡"] = df["5MA"]
new_df["10æ—¥å¹³å‡"] = df["10MA"]
new_df["20æ—¥å¹³å‡"] = df["20MA"]
new_df["5æ—¥ä¹–é›¢"] = df["5_Devi"]
new_df["10æ—¥ä¹–é›¢"] = df["10_Devi"]
new_df["20æ—¥ä¹–é›¢"] = df["20_Devi"]

# å‡ç·šä¸Šå‡å¹…åº¦
for n in [5, 10, 20]:
    col = f"{n}æ—¥å¹³å‡"
    new_df[f"{n}æ—¥ä¸Šå‡å¹…åº¦"] = new_df[col] - new_df[col].shift(1)

# æ‰£æŠµå€¼èˆ‡å½±éŸ¿ï¼ˆæ˜æ—¥æ˜¯å¦æ˜“ä¸Šæšçš„ç›´è¦ºæŒ‡æ¨™ï¼‰
new_df["5æ—¥æ‰£æŠµå€¼"] = new_df["æ”¶ç›¤åƒ¹"].shift(4)
new_df["10æ—¥æ‰£æŠµå€¼"] = new_df["æ”¶ç›¤åƒ¹"].shift(9)
new_df["20æ—¥æ‰£æŠµå€¼"] = new_df["æ”¶ç›¤åƒ¹"].shift(19)
for n in [5, 10, 20]:
    new_df[f"{n}æ—¥æ‰£æŠµå½±éŸ¿(%)"] = (new_df["æ”¶ç›¤åƒ¹"] - new_df[f"{n}æ—¥æ‰£æŠµå€¼"]) / new_df["æ”¶ç›¤åƒ¹"]

# å‡ç·šæ’åˆ—/æ–¹å‘/å¾—åˆ†/è·é›¢/ç‹€æ…‹
def judge_ma_type(r):
    a, b, c = r["5æ—¥å¹³å‡"], r["10æ—¥å¹³å‡"], r["20æ—¥å¹³å‡"]
    if pd.notna(a) and pd.notna(b) and pd.notna(c):
        if a > b > c:  return "å¤šé ­æ’åˆ—"
        if a < b < c:  return "ç©ºé ­æ’åˆ—"
    return "ç³¾çµ"
new_df["å‡ç·šæ’åˆ—"] = new_df.apply(judge_ma_type, axis=1)

for n in [5, 10, 20]:
    new_df[f"{n}æ—¥æ–œç‡"] = new_df[f"{n}æ—¥å¹³å‡"] - new_df[f"{n}æ—¥å¹³å‡"].shift(1)

def ma_score(r):
    s = 0
    for n in [5, 10, 20]:
        v = r[f"{n}æ—¥æ–œç‡"]
        if pd.isna(v): continue
        s += 1 if v > 0 else -1 if v < 0 else 0
    return s
new_df["å‡ç·šå¾—åˆ†"] = new_df.apply(ma_score, axis=1)
new_df["å‡ç·šæ–¹å‘"] = new_df["å‡ç·šå¾—åˆ†"].apply(lambda s: "ä¸Šæš" if s >= 2 else ("ä¸‹å½" if s <= -2 else "ç³¾çµ"))

new_df["å‡ç·šè·é›¢(%)"] = (
    (new_df[["5æ—¥å¹³å‡","10æ—¥å¹³å‡","20æ—¥å¹³å‡"]].max(axis=1) -
     new_df[["5æ—¥å¹³å‡","10æ—¥å¹³å‡","20æ—¥å¹³å‡"]].min(axis=1)) /
    new_df[["5æ—¥å¹³å‡","10æ—¥å¹³å‡","20æ—¥å¹³å‡"]].mean(axis=1) * 100
)
new_df["å‡ç·šç‹€æ…‹"] = new_df["å‡ç·šè·é›¢(%)"].apply(lambda x: "ç³¾çµ" if x < 0.5 else ("ç™¼æ•£" if x > 2 else "æ­£å¸¸"))

def trend_label(r):
    t, d, b = r["å‡ç·šæ’åˆ—"], r["å‡ç·šæ–¹å‘"], r["å‡ç·šè·é›¢(%)"]
    if t == "å¤šé ­æ’åˆ—" and d == "ä¸Šæš" and b > 2: return "ğŸš€ å¼·å‹¢å¤šé ­"
    if t == "å¤šé ­æ’åˆ—" and d == "ä¸Šæš":           return "ğŸŒ¤ï¸ ç©©å®šå¤šé ­"
    if t == "å¤šé ­æ’åˆ—" and d == "ä¸‹å½":           return "âš ï¸ å¤šé ­è½‰å¼±"
    if t == "ç©ºé ­æ’åˆ—" and d == "ä¸‹å½" and b > 2: return "ğŸ’£ å¼·å‹¢ç©ºé ­"
    if t == "ç©ºé ­æ’åˆ—" and d == "ä¸‹å½":           return "â˜ï¸ ç©©å®šç©ºé ­"
    if t == "ç©ºé ­æ’åˆ—" and d == "ä¸Šæš":           return "âš ï¸ ç©ºé ­è½‰å¼±"
    if r["å‡ç·šç‹€æ…‹"] == "ç³¾çµ":                    return "ğŸ¤ ç›¤æ•´å€é–“"
    return "â“ è¶¨å‹¢ä¸æ˜"
new_df["è¶¨å‹¢å¼·åº¦èªªæ˜"] = new_df.apply(trend_label, axis=1)

score_map = {
    "ğŸš€ å¼·å‹¢å¤šé ­": 3, "ğŸŒ¤ï¸ ç©©å®šå¤šé ­": 2, "âš ï¸ å¤šé ­è½‰å¼±": 1,
    "ğŸ¤ ç›¤æ•´å€é–“": 0, "âš ï¸ ç©ºé ­è½‰å¼±": -1, "â˜ï¸ ç©©å®šç©ºé ­": -2, "ğŸ’£ å¼·å‹¢ç©ºé ­": -3
}
new_df["è¶¨å‹¢ç­‰ç´š"] = new_df["è¶¨å‹¢å¼·åº¦èªªæ˜"].map(score_map).fillna(0)

# === 5/10/20 æ—¥ã€Œæœ€å¤§é‡ã€èˆ‡ã€Œæ—¥æœŸã€ ===
def rolling_max_with_date(vol_series: pd.Series, date_series: pd.Series, window: int):
    """
    å›å‚³ (æœ€å¤§é‡, å°æ‡‰æ—¥æœŸ)
    ä½¿ç”¨ pandas idxmax() çš„ rolling.apply å›å‚³ index ä½ç½®ï¼Œå†ç”¨ date_series å–æ—¥æœŸã€‚
    """
    # å…ˆæ‰¾åˆ°æ¯å€‹è¦–çª—å…§æœ€å¤§é‡çš„ index
    max_index = vol_series.rolling(window).apply(lambda x: x.idxmax(), raw=False)
    # å°æ‡‰æ—¥æœŸ
    max_date = max_index.map(lambda i: date_series.iloc[int(i)] if pd.notna(i) else pd.NaT)
    # æœ€å¤§å€¼
    max_val = vol_series.rolling(window).max()
    return max_val, max_date

new_df["æˆäº¤é‡"] = pd.to_numeric(new_df["æˆäº¤é‡"], errors="coerce")
for n in [5, 10, 20]:
    vmax, vdate = rolling_max_with_date(new_df["æˆäº¤é‡"], new_df["æ—¥æœŸ"], n)
    new_df[f"{n}æ—¥æœ€å¤§é‡"] = vmax
    new_df[f"{n}æ—¥æœ€å¤§é‡_æ—¥æœŸ"] = pd.to_datetime(vdate).dt.strftime("%Y-%m-%d")

# === æ¬„ä½é †åºï¼ˆå¼·åˆ¶è£œé½Šç¼ºæ¼ï¼‰ ===
columns_order = [
    "æ—¥æœŸ","è‚¡ç¥¨ä»£è™Ÿ",
    "é–‹ç›¤åƒ¹","æ”¶ç›¤åƒ¹","æ”¶ç›¤-é–‹ç›¤","æœ€é«˜åƒ¹","æœ€ä½åƒ¹","æ—¥æŒ¯å¹…","æ¼²è·Œå¹…(%)",
    "æˆäº¤é‡","é‡å¢ç‡(%)",
    "5æ—¥å‡é‡","5æ—¥æœ€å¤§é‡_æ—¥æœŸ","5æ—¥æœ€å¤§é‡",
    "10æ—¥å‡é‡","10æ—¥æœ€å¤§é‡_æ—¥æœŸ","10æ—¥æœ€å¤§é‡",
    "20æ—¥å‡é‡","20æ—¥æœ€å¤§é‡_æ—¥æœŸ","20æ—¥æœ€å¤§é‡",
    "å¯¦é«”(æ¼²è·Œç‡)","ä¸Šå½±(%)","ä¸Šå½±/å¯¦é«”","ä¸‹å½±(%)","ä¸‹å½±/å¯¦é«”","è·³ç©ºç¼ºå£",
    "5æ—¥å¹³å‡","10æ—¥å¹³å‡","20æ—¥å¹³å‡",
    "5æ—¥ä¸Šå‡å¹…åº¦","10æ—¥ä¸Šå‡å¹…åº¦","20æ—¥ä¸Šå‡å¹…åº¦",
    "5æ—¥æ‰£æŠµå€¼","5æ—¥æ‰£æŠµå½±éŸ¿(%)",
    "10æ—¥æ‰£æŠµå€¼","10æ—¥æ‰£æŠµå½±éŸ¿(%)",
    "20æ—¥æ‰£æŠµå€¼","20æ—¥æ‰£æŠµå½±éŸ¿(%)",
    "å‡ç·šå¾—åˆ†","å‡ç·šæ–¹å‘","å‡ç·šæ’åˆ—","å‡ç·šè·é›¢(%)","å‡ç·šç‹€æ…‹","è¶¨å‹¢å¼·åº¦èªªæ˜","è¶¨å‹¢ç­‰ç´š",
    "5æ—¥ä¹–é›¢","10æ—¥ä¹–é›¢","20æ—¥ä¹–é›¢",
    "ç¸½æˆäº¤é‡‘é¡(å„„)","æ³•äººç¸½è²·è¶…(å„„)","è²·è¶…-å¤–è³‡(å„„)","è²·è¶…-æŠ•ä¿¡(å„„)","è²·è¶…-è‡ªç‡Ÿå•†(å„„)","è²·è¶…-èè³‡(å„„)",
    "è³‡é‡‘èµ°å‘","è³‡é‡‘èµ°å‘åˆ¤è®€"
]
for c in columns_order:
    if c not in new_df.columns:
        new_df[c] = np.nan
new_df = new_df.reindex(columns=columns_order)

# === å„²å­˜ ===
outFile = f"{anaRootDir}/{sDt.strftime('%Y%m%d')}_{eDt.strftime('%Y%m%d')}-final_daily_report.csv"
new_df.to_csv(outFile, index=False, encoding="utf-8-sig")
print(f"âœ… å·²å®Œæˆå ±è¡¨ï¼š{outFile}")
