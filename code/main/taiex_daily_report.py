# python -m main.taiex_daily_report
import os
import pandas as pd
import numpy as np
from FinMind.data import DataLoader
from datetime import datetime
from dateutil.relativedelta import relativedelta
from module import twse

# === åŸºæœ¬è¨­å®š ===
token = "eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJkYXRlIjoiMjAyNS0xMC0wNCAxMzoxMjo1NyIsInVzZXJfaWQiOiJueWN1bGFiNjE1IiwiaXAiOiI0Mi43My41NS4xMDYifQ.YMhmYo6sx7_Z0WZwPbNcjDi8gPvt-a6bIx6XHeax4LM"
api = DataLoader()
api.login_by_token(api_token=token)

stockId = "TAIEX"
anaMonths = 2
forceRerun = False

# === æ—¥æœŸè¨­å®š ===
today = datetime.now()
sDt = today - relativedelta(months=anaMonths)
end_plus1 = (today + relativedelta(days=1)).strftime("%Y-%m-%d")

# === æª”æ¡ˆè·¯å¾‘ ===
anaRootDir = f"../Data/ana/anaKplot/{stockId}/{sDt.strftime('%Y%m')}"
os.makedirs(anaRootDir, exist_ok=True)
rawDir = f"../Data/finMind/taiwan_stock_daily_adj/{stockId}/{sDt.strftime('%Y%m')}"
os.makedirs(rawDir, exist_ok=True)
rawFile = f"{rawDir}/{sDt.strftime('%Y%m%d')}_{today.strftime('%Y%m%d')}.csv"

# === å¿«å–åˆ¤æ–· ===
def need_refresh(csv_path: str, date_col: str = "date") -> bool:
    if not os.path.exists(csv_path):
        return True
    try:
        tmp = pd.read_csv(csv_path)
        if date_col in tmp.columns:
            tmp[date_col] = pd.to_datetime(tmp[date_col])
            last = tmp[date_col].max().normalize()
            return last.date() < today.date()
        return True
    except Exception:
        return True

# === æŠ“æ—¥è³‡æ–™ ===
if not forceRerun and os.path.exists(rawFile) and not need_refresh(rawFile):
    df = pd.read_csv(rawFile)
else:
    df = api.taiwan_stock_daily_adj(
        stock_id=stockId,
        start_date=sDt.strftime("%Y-%m-%d"),
        end_date=end_plus1,
    )
    df.to_csv(rawFile, index=False, encoding="utf-8-sig")

df["date"] = pd.to_datetime(df["date"]).dt.tz_localize(None)
df = df[df["date"] <= pd.Timestamp(today.date())]
df = df.sort_values("date").reset_index(drop=True)

# === ä¸‰å¤§æ³•äºº ===
if stockId in ["TAIEX", "TPEx"]:
    miiDir = f"../Data/finMind/taiwan_stock_institutional_investors/all/{sDt.strftime('%Y%m')}"
else:
    miiDir = f"../Data/finMind/taiwan_stock_institutional_investors/{stockId}/{sDt.strftime('%Y%m')}"
os.makedirs(miiDir, exist_ok=True)
miiFile = f"{miiDir}/{sDt.strftime('%Y%m%d')}_{today.strftime('%Y%m%d')}-3mii.csv"

def load_or_fetch_mii():
    need = forceRerun or need_refresh(miiFile)
    if not need:
        return pd.read_csv(miiFile)
    if stockId in ["TAIEX", "TPEx"]:
        _df = api.taiwan_stock_institutional_investors_total(
            start_date=sDt.strftime("%Y-%m-%d"), end_date=end_plus1
        )
    else:
        _df = api.taiwan_stock_institutional_investors(
            stock_id=stockId, start_date=sDt.strftime("%Y-%m-%d"), end_date=end_plus1
        )
    _df.to_csv(miiFile, index=False, encoding="utf-8-sig")
    return _df

df_3mii = load_or_fetch_mii()

# === èè³‡ ===
df_margin = twse.get_margin_trading(sDt, today)
df_margin = df_margin[df_margin["é …ç›®"] == "èè³‡é‡‘é¡(ä»Ÿå…ƒ)"].copy()
df_margin["æ—¥æœŸ"] = pd.to_datetime(df_margin["æ—¥æœŸ"], format="%Y%m%d")

# === è¡ç”Ÿ ===
df = df.drop(columns=["spread", "Trading_turnover"], errors="ignore")
df["close-open"] = df["close"] - df["open"]
df["max-min"] = df["max"] - df["min"]
df["Volume_Change"] = (df["Trading_Volume"] - df["Trading_Volume"].shift(1)) / df["Trading_Volume"].shift(1)
for n in [5, 10, 20]:
    df[f"{n}æ—¥å‡é‡"] = df["Trading_Volume"].rolling(window=n).mean()
    df[f"{n}MA"] = df["close"].rolling(window=n).mean()
    df[f"{n}_Devi"] = (df["close"] - df[f"{n}MA"]) / df[f"{n}MA"]

# === åˆä½µæ³•äºº ===
if df_3mii.empty:
    df_3mii = pd.DataFrame(columns=["buy", "sell", "date", "name"])
df_3mii["net_buy"] = df_3mii["buy"] - df_3mii["sell"]
df_3mii["date"] = pd.to_datetime(df_3mii["date"])
map_name = {
    "Foreign_Investor": "è²·è¶…-å¤–è³‡",
    "Investment_Trust": "è²·è¶…-æŠ•ä¿¡",
    "Dealer_self": "è²·è¶…-è‡ªç‡Ÿå•†(è‡ªè¡Œè²·è³£)",
    "Dealer_Hedging": "è²·è¶…-è‡ªç‡Ÿå•†(é¿éšª)",
    "Foreign_Dealer_Self": "è²·è¶…-å¤–è³‡è‡ªç‡Ÿå•†",
    "total": "æ³•äººç¸½è²·è¶…",
}
df_3mii["col_name"] = df_3mii["name"].map(map_name)
df_3mii_wide = df_3mii.pivot(index="date", columns="col_name", values="net_buy").reset_index()
df_merged = df.merge(df_3mii_wide, on="date", how="left")

# === åˆä½µèè³‡ ===
df_merged = df_merged.merge(df_margin[["æ—¥æœŸ", "ä»Šæ—¥é¤˜é¡"]], left_on="date", right_on="æ—¥æœŸ", how="left")
df_merged.drop(columns=["æ—¥æœŸ"], inplace=True)
df_merged["èè³‡é¤˜é¡(å„„)"] = pd.to_numeric(df_merged["ä»Šæ—¥é¤˜é¡"], errors="coerce") * 1000 / 1e8
df_merged["èè³‡å¢æ¸›(å„„)"] = df_merged["èè³‡é¤˜é¡(å„„)"] - df_merged["èè³‡é¤˜é¡(å„„)"].shift(1)

# === è³‡é‡‘èµ°å‘ ===
df_merged["è³‡é‡‘èµ°å‘"] = df_merged["close-open"] - (
    (pd.to_numeric(df_merged.get("æ³•äººç¸½è²·è¶…"), errors="coerce") / 1e8) + df_merged["èè³‡å¢æ¸›(å„„)"]
)
df_merged["è³‡é‡‘èµ°å‘åˆ¤è®€"] = df_merged["è³‡é‡‘èµ°å‘"].apply(
    lambda x: "åé‡å¤§å‹è‚¡(å¤š)" if x > 0 else ("åé‡å°å‹è‚¡(ç©º)" if x < 0 else None)
)

# === ä¸­æ–‡æ¬„ä½ ===
rename_dict = {
    "date": "æ—¥æœŸ",
    "stock_id": "è‚¡ç¥¨ä»£è™Ÿ",
    "Trading_Volume": "æˆäº¤é‡",
    "Volume_Change": "é‡å¢ç‡(%)",
    "Trading_money": "ç¸½æˆäº¤é‡‘é¡(å„„)",
    "open": "é–‹ç›¤åƒ¹",
    "max": "æœ€é«˜åƒ¹",
    "min": "æœ€ä½åƒ¹",
    "close": "æ”¶ç›¤åƒ¹",
    "close-open": "æ”¶ç›¤-é–‹ç›¤",
    "max-min": "æ—¥æŒ¯å¹…",
    "5MA": "5æ—¥å¹³å‡",
    "10MA": "10æ—¥å¹³å‡",
    "20MA": "20æ—¥å¹³å‡",
    "5_Devi": "5æ—¥ä¹–é›¢",
    "10_Devi": "10æ—¥ä¹–é›¢",
    "20_Devi": "20æ—¥ä¹–é›¢",
    "æ³•äººç¸½è²·è¶…": "æ³•äººç¸½è²·è¶…(å„„)",
    "è²·è¶…-å¤–è³‡": "è²·è¶…-å¤–è³‡(å„„)",
    "è²·è¶…-æŠ•ä¿¡": "è²·è¶…-æŠ•ä¿¡(å„„)",
    "èè³‡å¢æ¸›(å„„)": "è²·è¶…-èè³‡(å„„)",
}
new_df = df_merged.rename(columns=rename_dict).copy()

# === é‡‘é¡æ›ç®— ===
for col in ["ç¸½æˆäº¤é‡‘é¡(å„„)", "æ³•äººç¸½è²·è¶…(å„„)", "è²·è¶…-å¤–è³‡(å„„)", "è²·è¶…-æŠ•ä¿¡(å„„)",
            "è²·è¶…-è‡ªç‡Ÿå•†(è‡ªè¡Œè²·è³£)", "è²·è¶…-è‡ªç‡Ÿå•†(é¿éšª)", "è²·è¶…-å¤–è³‡è‡ªç‡Ÿå•†"]:
    if col in new_df.columns:
        new_df[col] = pd.to_numeric(new_df[col], errors="coerce") / 1e8

new_df["è²·è¶…-è‡ªç‡Ÿå•†(å„„)"] = (
    pd.to_numeric(new_df.get("è²·è¶…-å¤–è³‡è‡ªç‡Ÿå•†"), errors="coerce").fillna(0)
    + pd.to_numeric(new_df.get("è²·è¶…-è‡ªç‡Ÿå•†(è‡ªè¡Œè²·è³£)"), errors="coerce").fillna(0)
    + pd.to_numeric(new_df.get("è²·è¶…-è‡ªç‡Ÿå•†(é¿éšª)"), errors="coerce").fillna(0)
)

# === åƒ¹ / ç·šå‹ ===
new_df["æ¼²è·Œå¹…(%)"] = (new_df["æ”¶ç›¤åƒ¹"] - new_df["æ”¶ç›¤åƒ¹"].shift(1)) / new_df["æ”¶ç›¤åƒ¹"].shift(1)
new_df["å¯¦é«”(æ¼²è·Œç‡)"] = (new_df["æ”¶ç›¤åƒ¹"] - new_df["é–‹ç›¤åƒ¹"]) / new_df["é–‹ç›¤åƒ¹"]

is_red = new_df["æ”¶ç›¤åƒ¹"] >= new_df["é–‹ç›¤åƒ¹"]
new_df["ä¸Šå½±(%)"] = np.where(is_red, (new_df["æœ€é«˜åƒ¹"] - new_df["æ”¶ç›¤åƒ¹"]) / new_df["æœ€é«˜åƒ¹"],
                            (new_df["æœ€é«˜åƒ¹"] - new_df["é–‹ç›¤åƒ¹"]) / new_df["æœ€é«˜åƒ¹"])
new_df["ä¸‹å½±(%)"] = np.where(is_red, (new_df["é–‹ç›¤åƒ¹"] - new_df["æœ€ä½åƒ¹"]) / new_df["æœ€ä½åƒ¹"],
                            (new_df["æ”¶ç›¤åƒ¹"] - new_df["æœ€ä½åƒ¹"]) / new_df["æœ€ä½åƒ¹"])

# === å‡ç·š ===
for n in [5, 10, 20]:
    new_df[f"{n}æ—¥ä¸Šå‡å¹…åº¦"] = new_df[f"{n}æ—¥å¹³å‡"] - new_df[f"{n}æ—¥å¹³å‡"].shift(1)
    new_df[f"{n}æ—¥æ‰£æŠµå€¼"] = new_df["æ”¶ç›¤åƒ¹"].shift(n-1)
    new_df[f"{n}æ—¥æ‰£æŠµå½±éŸ¿(%)"] = (new_df["æ”¶ç›¤åƒ¹"] - new_df[f"{n}æ—¥æ‰£æŠµå€¼"]) / new_df["æ”¶ç›¤åƒ¹"]

# === å‡ç·šæ’åˆ—èˆ‡è¶¨å‹¢ ===
for n in [5, 10, 20]:
    new_df[f"{n}æ—¥æ–œç‡"] = new_df[f"{n}æ—¥å¹³å‡"] - new_df[f"{n}æ—¥å¹³å‡"].shift(1)

def judge_ma_type(r):
    a, b, c = r["5æ—¥å¹³å‡"], r["10æ—¥å¹³å‡"], r["20æ—¥å¹³å‡"]
    if pd.notna(a) and pd.notna(b) and pd.notna(c):
        if a > b > c: return "å¤šé ­æ’åˆ—"
        if a < b < c: return "ç©ºé ­æ’åˆ—"
    return "ç³¾çµ"

new_df["å‡ç·šæ’åˆ—"] = new_df.apply(judge_ma_type, axis=1)

def ma_score(r):
    s = 0
    for n in [5, 10, 20]:
        v = r[f"{n}æ—¥æ–œç‡"]
        if pd.isna(v): continue
        s += 1 if v > 0 else -1 if v < 0 else 0
    return s

new_df["å‡ç·šå¾—åˆ†"] = new_df.apply(ma_score, axis=1)
new_df["å‡ç·šæ–¹å‘"] = new_df["å‡ç·šå¾—åˆ†"].apply(lambda s: "ä¸Šæš" if s >= 2 else ("ä¸‹å½" if s <= -2 else "ç³¾çµ"))
new_df["å‡ç·šè·é›¢(%)"] = (
    (new_df[["5æ—¥å¹³å‡", "10æ—¥å¹³å‡", "20æ—¥å¹³å‡"]].max(axis=1)
     - new_df[["5æ—¥å¹³å‡", "10æ—¥å¹³å‡", "20æ—¥å¹³å‡"]].min(axis=1))
    / new_df[["5æ—¥å¹³å‡", "10æ—¥å¹³å‡", "20æ—¥å¹³å‡"]].mean(axis=1) * 100
)
new_df["å‡ç·šç‹€æ…‹"] = new_df["å‡ç·šè·é›¢(%)"].apply(lambda x: "ç³¾çµ" if x < 0.5 else ("ç™¼æ•£" if x > 2 else "æ­£å¸¸"))

def trend_label(r):
    t, d, b = r["å‡ç·šæ’åˆ—"], r["å‡ç·šæ–¹å‘"], r["å‡ç·šè·é›¢(%)"]
    if t == "å¤šé ­æ’åˆ—" and d == "ä¸Šæš" and b > 2: return "ğŸš€ å¼·å‹¢å¤šé ­"
    if t == "å¤šé ­æ’åˆ—" and d == "ä¸Šæš": return "ğŸŒ¤ï¸ ç©©å®šå¤šé ­"
    if t == "å¤šé ­æ’åˆ—" and d == "ä¸‹å½": return "âš ï¸ å¤šé ­è½‰å¼±"
    if t == "ç©ºé ­æ’åˆ—" and d == "ä¸‹å½" and b > 2: return "ğŸ’£ å¼·å‹¢ç©ºé ­"
    if t == "ç©ºé ­æ’åˆ—" and d == "ä¸‹å½": return "â˜ï¸ ç©©å®šç©ºé ­"
    if t == "ç©ºé ­æ’åˆ—" and d == "ä¸Šæš": return "âš ï¸ ç©ºé ­è½‰å¼±"
    if r["å‡ç·šç‹€æ…‹"] == "ç³¾çµ": return "ğŸ¤ ç›¤æ•´å€é–“"
    return "â“ è¶¨å‹¢ä¸æ˜"

new_df["è¶¨å‹¢å¼·åº¦èªªæ˜"] = new_df.apply(trend_label, axis=1)
score_map = {"ğŸš€ å¼·å‹¢å¤šé ­":3,"ğŸŒ¤ï¸ ç©©å®šå¤šé ­":2,"âš ï¸ å¤šé ­è½‰å¼±":1,"ğŸ¤ ç›¤æ•´å€é–“":0,"âš ï¸ ç©ºé ­è½‰å¼±":-1,"â˜ï¸ ç©©å®šç©ºé ­":-2,"ğŸ’£ å¼·å‹¢ç©ºé ­":-3}
new_df["è¶¨å‹¢ç­‰ç´š"] = new_df["è¶¨å‹¢å¼·åº¦èªªæ˜"].map(score_map).fillna(0)

# === é‡èƒ½æœ€å¤§é‡ ===
new_df["æˆäº¤é‡"] = pd.to_numeric(new_df["æˆäº¤é‡"], errors="coerce")
# === 5/10/20 æ—¥æœ€å¤§é‡èˆ‡æ—¥æœŸ ===
for n in [5, 10, 20]:
    vmax_list, vdate_list = [], []
    vols = new_df["æˆäº¤é‡"].to_numpy()
    dates = pd.to_datetime(new_df["æ—¥æœŸ"]).dt.strftime("%Y-%m-%d").to_numpy()

    for i in range(len(new_df)):
        if i + 1 < n:
            vmax_list.append(np.nan)
            vdate_list.append(np.nan)
            continue

        # çœ‹è¿‘ n å¤©
        window_vol = vols[i + 1 - n : i + 1]
        window_date = dates[i + 1 - n : i + 1]

        # æ‰¾æœ€å¤§æˆäº¤é‡çš„ index
        idx = int(np.argmax(window_vol))
        vmax_list.append(window_vol[idx])
        vdate_list.append(window_date[idx])

    new_df[f"{n}æ—¥æœ€å¤§é‡"] = vmax_list
    new_df[f"{n}æ—¥æœ€å¤§é‡_æ—¥æœŸ"] = vdate_list
# === æ¬„ä½é †åº ===
columns_order = [
    "æ—¥æœŸ","è‚¡ç¥¨ä»£è™Ÿ",
    "é–‹ç›¤åƒ¹","æ”¶ç›¤åƒ¹","æ”¶ç›¤-é–‹ç›¤","æœ€é«˜åƒ¹","æœ€ä½åƒ¹","æ—¥æŒ¯å¹…","æ¼²è·Œå¹…(%)",
    "æˆäº¤é‡","é‡å¢ç‡(%)",
    "5æ—¥å‡é‡","5æ—¥æœ€å¤§é‡_æ—¥æœŸ","5æ—¥æœ€å¤§é‡",
    "10æ—¥å‡é‡","10æ—¥æœ€å¤§é‡_æ—¥æœŸ","10æ—¥æœ€å¤§é‡",
    "20æ—¥å‡é‡","20æ—¥æœ€å¤§é‡_æ—¥æœŸ","20æ—¥æœ€å¤§é‡",
    "å¯¦é«”(æ¼²è·Œç‡)","ä¸Šå½±(%)","ä¸‹å½±(%)","ä¸Šå½±/å¯¦é«”","ä¸‹å½±/å¯¦é«”","è·³ç©ºç¼ºå£",
    "5æ—¥å¹³å‡","10æ—¥å¹³å‡","20æ—¥å¹³å‡",
    "5æ—¥ä¸Šå‡å¹…åº¦","10æ—¥ä¸Šå‡å¹…åº¦","20æ—¥ä¸Šå‡å¹…åº¦",
    "5æ—¥æ‰£æŠµå€¼","5æ—¥æ‰£æŠµå½±éŸ¿(%)","10æ—¥æ‰£æŠµå€¼","10æ—¥æ‰£æŠµå½±éŸ¿(%)","20æ—¥æ‰£æŠµå€¼","20æ—¥æ‰£æŠµå½±éŸ¿(%)",
    "å‡ç·šå¾—åˆ†","å‡ç·šæ–¹å‘","å‡ç·šæ’åˆ—","å‡ç·šè·é›¢(%)","å‡ç·šç‹€æ…‹","è¶¨å‹¢å¼·åº¦èªªæ˜","è¶¨å‹¢ç­‰ç´š",
    "5æ—¥ä¹–é›¢","10æ—¥ä¹–é›¢","20æ—¥ä¹–é›¢",
    "ç¸½æˆäº¤é‡‘é¡(å„„)","æ³•äººç¸½è²·è¶…(å„„)","è²·è¶…-å¤–è³‡(å„„)","è²·è¶…-æŠ•ä¿¡(å„„)","è²·è¶…-è‡ªç‡Ÿå•†(å„„)","è²·è¶…-èè³‡(å„„)",
    "è³‡é‡‘èµ°å‘","è³‡é‡‘èµ°å‘åˆ¤è®€"
]
for c in columns_order:
    if c not in new_df.columns:
        new_df[c] = np.nan
new_df = new_df.reindex(columns=columns_order)

# === å„²å­˜ ===
outFile = f"{anaRootDir}/{sDt.strftime('%Y%m%d')}_{today.strftime('%Y%m%d')}-final_daily_report.csv"
new_df.to_csv(outFile, index=False, encoding="utf-8")
