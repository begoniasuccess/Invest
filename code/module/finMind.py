import sys
import os
from datetime import datetime
import pandas as pd
from FinMind.data import DataLoader 
from common import utils,db
import requests
from typing import Union, Iterable

sys.stdout.reconfigure(encoding='utf-8')

### FinMind apiè¨­å®š
apiUrl = "https://api.finmindtrade.com/api/v4/data"
api = DataLoader()
token = "eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJkYXRlIjoiMjAyNS0xMi0yMiAyMDoxOTo1OSIsInVzZXJfaWQiOiJueWN1bGFiNjE1IiwiaXAiOiIyMjMuMTQzLjE5NC45In0.cpV6AuW_6FhXhZXvvnyKhFojvH7gBML9ipthkfNwIUo"
api.login_by_token(api_token=token)

storageDir = "../data/FinMind"
os.makedirs(storageDir, exist_ok=True)

storageDir_twStockInfo =  f"{storageDir}/TW/StockInfo"
os.makedirs(storageDir_twStockInfo, exist_ok=True)

def getDataLoader() -> DataLoader:
    return api

# æ’ˆå–å°è‚¡æ¸…å–®
def twStockInfo(includeCateHistory:bool=False) -> pd.DataFrame:
    df = None
    output_file = f"{storageDir_twStockInfo}/stock_info.csv"
    if os.path.exists(output_file):
        df = pd.read_csv(output_file)
        print(f"â˜‘ï¸ Data exist: {output_file}")
    else:        
        df = api.taiwan_stock_info() # å°è‚¡ç¸½è¦½
        df['date'] = pd.to_datetime(df['date'], errors='coerce') 
        df = df[df['date'].notna()] 
        if not includeCateHistory:
            # ç¢ºä¿ date æ¬„ä½æ˜¯ datetime æ ¼å¼
            df['date'] = pd.to_datetime(df['date'])

            # ä¾ stock_id åˆ†çµ„ï¼Œé¸å–æ¯çµ„ä¸­ date æœ€å¤§çš„é‚£ç­†è³‡æ–™
            latest_df = df.sort_values('date').groupby('stock_id', as_index=False).tail(1)

            # ä¾ç…§ stock_id æ’åºï¼ˆå¯é¸ï¼‰
            df = latest_df.sort_values(by='stock_id')
        df.to_csv(output_file, index=False, encoding='utf-8-sig')
    return df

# æ’ˆå–ä¸Šå¸‚æ¸…å–®
def twStockInfoTwse(includeCateHistory:bool=False) -> pd.DataFrame:
    df_twse_filtered = None
    output_file = f"{storageDir_twStockInfo}/stock_info-twse.csv"
    if os.path.exists(output_file):
        df = pd.read_csv(output_file)
        print(f"â˜‘ï¸ Data exist: {output_file}")
        return df
    else:        
        df = twStockInfo(includeCateHistory)
        
        # ç¯©é¸ type ç‚º 'twse' (ä¸Šå¸‚)
        df_twse = df[df['type'] == 'twse']

        # æ’é™¤ industry_category æ¬„ä½å«æœ‰æŒ‡å®šé—œéµå­—çš„è³‡æ–™
        exclude_keywords = ['ETF', 'Index', 'å—ç›Šè­‰åˆ¸', 'ETN', 'å¤§ç›¤', 'å­˜è¨—æ†‘è­‰', 'å‰µæ–°æ¿è‚¡ç¥¨', 'å‰µæ–°ç‰ˆè‚¡ç¥¨']
        pattern = '|'.join(exclude_keywords)  # å»ºç«‹ regex æ¨¡å¼
        df_twse_filtered = df_twse[~df_twse['industry_category'].str.contains(pattern, na=False)]

        df_twse_filtered.to_csv(output_file, index=False, encoding='utf-8-sig')
    return df_twse_filtered

# æ’é™¤èˆˆæ«ƒçš„å°è‚¡æ¸…å–®
def twStockInfoNoEmerging(includeCateHistory:bool=False) -> pd.DataFrame:
    df_twse_filtered = None
    output_file = f"{storageDir_twStockInfo}/stock_info-no_emerging.csv"
    if os.path.exists(output_file):
        df_twse_filtered = pd.read_csv(output_file)
        print(f"â˜‘ï¸ Data exist: {output_file}")
    else:          
        df = twStockInfo(includeCateHistory)
        
        # æ’é™¤ type ç‚º 'emerging' (èˆˆæ«ƒ)
        df_twse = df[df['type'] != 'emerging']

        # æ’é™¤ industry_category æ¬„ä½å«æœ‰æŒ‡å®šé—œéµå­—çš„è³‡æ–™
        exclude_keywords = ['ETF', 'Index', 'å—ç›Šè­‰åˆ¸', 'ETN', 'å¤§ç›¤', 'å­˜è¨—æ†‘è­‰', 'å‰µæ–°æ¿è‚¡ç¥¨', 'å‰µæ–°ç‰ˆè‚¡ç¥¨']
        pattern = '|'.join(exclude_keywords)  # å»ºç«‹ regex æ¨¡å¼
        df_twse_filtered = df_twse[~df_twse['industry_category'].str.contains(pattern, na=False)]

        df_twse_filtered.to_csv(output_file, index=False, encoding='utf-8-sig')
    return df_twse_filtered

storageDir_twMarketValue =  f"{storageDir}/TW/MarketValue"
os.makedirs(storageDir_twMarketValue, exist_ok=True)

# æ’ˆå–å„è‚¡ç¥¨å¸‚å€¼è³‡æ–™ï¼ˆé€å¹´å­˜æª”ï¼‰
def runTwMarketValue(stockList: list, sDt: datetime, eDt: datetime) -> bool:
    result = True
    try:
        utils.ptMsg("ğŸ“¢ å³å°‡æ’ˆå–[å¸‚å€¼æ­·å²]è³‡æ–™ï¼ˆé€å¹´å­˜æª”ï¼‰ï¼Œè‚¡ç¥¨æ¸…å–®é•·åº¦ï¼š", len(stockList))

        outputDir = storageDir_twMarketValue

        for stock_id in stockList:
            cur_year = sDt.year
            end_year = eDt.year

            while cur_year <= end_year:
                year_start = datetime(cur_year, 1, 1)
                year_end = datetime(cur_year, 12, 31)
                if year_end > eDt:
                    year_end = eDt
                if year_start < sDt:
                    year_start = sDt

                outputFile = f"{outputDir}/{cur_year}/TWMV-{stock_id}.csv"

                if os.path.exists(outputFile):
                    utils.ptMsg("â˜‘ï¸ æª”æ¡ˆå·²å­˜åœ¨ï¼š", outputFile)
                else:
                    os.makedirs(os.path.dirname(outputFile), exist_ok=True)
                    try:
                        utils.ptMsg(f"â¡ï¸ æ’ˆå– {stock_id} å¹´åº¦ï¼š{cur_year}ï¼ˆ{year_start.date()} ~ {year_end.date()}ï¼‰")
                        dfMV = api.taiwan_stock_market_value(
                            stock_id=stock_id,
                            start_date=year_start.strftime("%Y-%m-%d"),
                            end_date=year_end.strftime("%Y-%m-%d")
                        )
                        dfMV.to_csv(outputFile, index=False, encoding='utf-8-sig')
                        utils.ptMsg("âœ… æª”æ¡ˆå­˜å–æˆåŠŸï¼š", outputFile)
                    except Exception as e:
                        utils.ptMsg(f"âŒ {stock_id} å¹´åº¦ {cur_year} æŠ“å–å¤±æ•—ï¼ŒéŒ¯èª¤è¨Šæ¯ï¼š{e}")
                        # ä¸ raiseï¼Œç¹¼çºŒè·‘å…¶ä»–å¹´åº¦

                cur_year += 1

        utils.ptMsg("ğŸ“¢ [å¸‚å€¼æ­·å²]è³‡æ–™æ’ˆå–çµæŸã€‚")

    except Exception as e:
        utils.ptMsg(f"ç™¼ç”ŸéŒ¯èª¤ï¼š{e}")
        return False

    return result

storageDir_twDailyPriceAdj =  f"{storageDir}/TW/DailyPriceAdj"
os.makedirs(storageDir_twStockInfo, exist_ok=True)

# æ’ˆå–è‚¡ç¥¨æ¯æ—¥èª¿æ•´å¾Œåƒ¹æ ¼ï¼ˆé€å¹´å­˜æª”ï¼‰
def runTwStockDailyPriceAdj(stockList: list, sDt: datetime, eDt: datetime, outputDir: str=None) -> bool:
    result = True
    try:
        utils.ptMsg("ğŸ“¢ å³å°‡æ’ˆå–[æ­·å²ä¿®æ­£è‚¡åƒ¹]è³‡æ–™ï¼ˆé€å¹´å­˜æª”ï¼‰ï¼Œè‚¡ç¥¨æ¸…å–®é•·åº¦ï¼š", len(stockList))
        if outputDir is None:
            outputDir = storageDir_twDailyPriceAdj

        for stock_id in stockList:
            cur_year = sDt.year
            end_year = eDt.year

            while cur_year <= end_year:
                year_start = datetime(cur_year, 1, 1)
                year_end = datetime(cur_year, 12, 31)
                # ç¢ºä¿ä¸è¶…éæŒ‡å®šçš„ eDt
                if year_end > eDt:
                    year_end = eDt
                if year_start < sDt:
                    year_start = sDt

                outputFile = f'{outputDir}/{cur_year}/TWDPadj-{stock_id}.csv'

                if os.path.exists(outputFile):
                    utils.ptMsg("â˜‘ï¸ æª”æ¡ˆå·²å­˜åœ¨ï¼š", outputFile)
                else:
                    os.makedirs(os.path.dirname(outputFile), exist_ok=True)
                    try:
                        utils.ptMsg(f"â¡ï¸ æ’ˆå– {stock_id} å¹´åº¦ï¼š{cur_year}ï¼ˆ{year_start.date()} ~ {year_end.date()}ï¼‰")
                        dfSDA = api.taiwan_stock_daily_adj(
                            stock_id=stock_id,
                            start_date=year_start.strftime("%Y-%m-%d"),
                            end_date=year_end.strftime("%Y-%m-%d")
                        )
                        dfSDA.to_csv(outputFile, index=False, encoding='utf-8-sig')
                        utils.ptMsg("âœ… æª”æ¡ˆå­˜å–æˆåŠŸï¼š", outputFile)
                    except Exception as e:
                        utils.ptMsg(f"âŒ {stock_id} å¹´åº¦ {cur_year} æŠ“å–å¤±æ•—ï¼ŒéŒ¯èª¤è¨Šæ¯ï¼š{e}")
                        # ä¸è¦ raiseï¼Œç¹¼çºŒæŠ“ä¸‹ä¸€å¹´
                cur_year += 1

    except Exception as e:
        utils.ptMsg(f"ç™¼ç”Ÿé‡å¤§éŒ¯èª¤ï¼š{e}")
        return False

    return result

# å–å¾—åŠ æ¬ŠæŒ‡æ•¸çš„èª¿æ•´å¾Œåƒ¹æ ¼          
def getWeightIdxDailyPriceAdj(sDt: datetime, eDt: datetime) -> bool:    
    # outputDir = f'{storageDir_twDailyPriceAdj}/weightIdx'
    stockList = ['TAIEX']
    return runTwStockDailyPriceAdj(stockList, sDt, eDt)

# å–å¾—å°è‚¡çš„æ‰€æœ‰äº¤æ˜“æ—¥æœŸ
def getTwStockTradingDates() -> pd.DataFrame:
    fileDir = "../data/FinMind/TW/StockInfo/twStockTradingDate.csv"
    url = "https://api.finmindtrade.com/api/v4/data"
    parameter = {"dataset": "TaiwanStockTradingDate"}

    # ===== æª”æ¡ˆå­˜åœ¨ï¼Œå…ˆè®€èˆŠè³‡æ–™ =====
    if os.path.exists(fileDir):
        df_local = pd.read_csv(fileDir)
        try:
            last_local_date = pd.to_datetime(df_local["date"].max()).date()
        except Exception:
            last_local_date = None
    else:
        df_local = None
        last_local_date = None

    # ===== æª¢æŸ¥æ˜¯å¦éœ€è¦æ›´æ–° =====
    resp = requests.get(url, params=parameter)
    data = pd.DataFrame(resp.json()["data"])
    last_online_date = pd.to_datetime(data["date"].max()).date()

    need_update = (
        last_local_date is None or
        last_local_date < last_online_date
    )

    if need_update:
        # æ›´æ–°è³‡æ–™ä¸¦è¦†è“‹
        os.makedirs(os.path.dirname(fileDir), exist_ok=True)
        data.to_csv(fileDir, index=False, encoding="utf-8-sig")
        print(f"âœ… å·²æ›´æ–°äº¤æ˜“æ—¥æ›†è‡³ {last_online_date}")
        return data
    else:
        print(f"ğŸ“ ä½¿ç”¨æœ¬åœ°å¿«å–ï¼šå·²æ˜¯æœ€æ–°è‡³ {last_local_date}")
        return df_local

# å–å¾—å°è‚¡æ—¥è³‡æ–™
def get_tw_stock_daily_price(
    stock_id: Union[str, list[str]],
    start_date: datetime,
    end_date: datetime,
) -> pd.DataFrame:
    print(f"--- run finMind.get_tw_stock_daily_price--[{stock_id}]")
    target_table = "fm_taiwan_stock_daily"

    # === 0) stock_id æ­£è¦åŒ– ===
    if isinstance(stock_id, str):
        stock_ids = [stock_id]
    else:
        stock_ids = list(stock_id)

    req_s = pd.Timestamp(start_date).normalize()
    req_e = pd.Timestamp(end_date).normalize()
    if req_s > req_e:
        raise ValueError("start_date ä¸å¯å¤§æ–¼ end_date")

    def dstr(t: pd.Timestamp) -> str:
        return t.strftime("%Y-%m-%d")

    all_dfs: list[pd.DataFrame] = []

    # === 1) é€æª”è™•ç† ===
    for sid in stock_ids:

        # --- æŸ¥ span ---
        span_row = db.query_to_df(
            """
            SELECT start_date, end_date
            FROM stock_span
            WHERE target_table = ? AND stock_id = ?
            """,
            (target_table, sid),
        )

        mem_s = pd.Timestamp(span_row.loc[0, "start_date"]).normalize() if not span_row.empty else None
        mem_e = pd.Timestamp(span_row.loc[0, "end_date"]).normalize() if not span_row.empty else None

        fetch_ranges: list[tuple[pd.Timestamp, pd.Timestamp]] = []

        if mem_s is None:
            fetch_ranges = [(req_s, req_e)]
            new_s, new_e = req_s, req_e
        else:
            new_s = min(mem_s, req_s)
            new_e = max(mem_e, req_e)

            if req_s >= mem_s and req_e <= mem_e:
                fetch_ranges = []
            elif req_s > mem_e:
                fetch_ranges = [(mem_e + pd.Timedelta(days=1), req_e)]
            elif req_e < mem_s:
                fetch_ranges = [(req_s, mem_s - pd.Timedelta(days=1))]
            else:
                if req_s < mem_s:
                    fetch_ranges.append((req_s, mem_s - pd.Timedelta(days=1)))
                if req_e > mem_e:
                    fetch_ranges.append((mem_e + pd.Timedelta(days=1), req_e))

        # --- è£œè³‡æ–™ ---
        upsert_sql = f"""
        INSERT INTO {target_table}
        (date, stock_id, Trading_Volume, Trading_money, open, max, min, close, spread, Trading_turnover)
        VALUES (?,?,?,?,?,?,?,?,?,?)
        ON CONFLICT(date, stock_id) DO UPDATE SET
          Trading_Volume   = excluded.Trading_Volume,
          Trading_money    = excluded.Trading_money,
          open             = excluded.open,
          max              = excluded.max,
          min              = excluded.min,
          close            = excluded.close,
          spread           = excluded.spread,
          Trading_turnover = excluded.Trading_turnover
        """

        for fs, fe in fetch_ranges:
            if fs <= fe:
                df_api = api.taiwan_stock_daily(
                    stock_id=sid,
                    start_date=dstr(fs),
                    end_date=dstr(fe),
                )
                if df_api is not None and not df_api.empty:
                    df_api = df_api.copy()
                    df_api["date"] = pd.to_datetime(df_api["date"]).dt.strftime("%Y-%m-%d")
                    df_api["stock_id"] = df_api["stock_id"].astype(str)

                    params = list(df_api[
                        ["date", "stock_id", "Trading_Volume", "Trading_money",
                         "open", "max", "min", "close", "spread", "Trading_turnover"]
                    ].itertuples(index=False, name=None))

                    db.execute_sql(upsert_sql, params)

        # --- æ›´æ–° span ---
        db.execute_sql(
            """
            INSERT INTO stock_span (target_table, stock_id, start_date, end_date, updated_at)
            VALUES (?, ?, ?, ?, strftime('%s','now'))
            ON CONFLICT(target_table, stock_id) DO UPDATE SET
              start_date = excluded.start_date,
              end_date   = excluded.end_date,
              updated_at = strftime('%s','now')
            """,
            (target_table, sid, dstr(new_s), dstr(new_e)),
        )

        # --- DB å›å‚³è©²æª” ---
        df_sid = db.query_to_df(
            f"""
            SELECT date, stock_id, Trading_Volume, Trading_money,
                   open, max, min, close, spread, Trading_turnover
            FROM {target_table}
            WHERE stock_id = ?
              AND date >= ?
              AND date <= ?
            ORDER BY date
            """,
            (sid, dstr(req_s), dstr(req_e)),
        )

        all_dfs.append(df_sid)

    # === 2) åˆä½µå›å‚³ ===
    if not all_dfs:
        return pd.DataFrame()

    return pd.concat(all_dfs, ignore_index=True)

# python -m module.finMind
if __name__ == "__main__":
    stock_id = ['0050']
    sDt = datetime(2025, 12, 1)
    eDt = datetime.now()
    df = get_tw_stock_daily_price(stock_id, sDt, eDt)
    
    print(df.head(), df.tail())
    
